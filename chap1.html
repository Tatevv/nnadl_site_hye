<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
<head>
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Neural networks and deep learning</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS":
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('https://cdn.mathjax.org/mathjax/latest/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>

  </head>
  <body>
    <div class="nonumber_header">
      <h2><a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a></h2>
    </div>
    <div class="section">
      <div id="toc">
        <p class="toc_title">
          <a href="index.html">Նեյրոնային ցանցեր և խորը ուսուցում</a>
        </p>
        <p class="toc_not_mainchapter">
          <a href="about.html">Ինչի՞ մասին է գիրքը</a>
        </p>
        <p class="toc_not_mainchapter">
          <a href="exercises_and_problems.html">Խնդիրների և վարժությունների մասին</a>
        </p>
        <p class='toc_mainchapter'>
          <a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a>
          <a href="chap1.html">Ձեռագիր թվանշանների ճանաչում՝ օգտագործելով նեյրոնային ցանցեր</a>
          <div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;">
            <p class="toc_section">
              <ul>
                <a href="chap1.html#perceptrons"><li>Պերսեպտրոններ</li></a>
                <a href="chap1.html#sigmoid_neurons"><li>Սիգմոիդ նեյրոններ</li></a>
                <a href="chap1.html#the_architecture_of_neural_networks"><li>Նեյրոնային ցանցերի կառուցվածքը</li></a>
                <a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>Պարզ ցանց ձեռագիր թվանշանների ճանաչման համար</li></a>
                <a href="chap1.html#learning_with_gradient_descent"><li>Ուսուցում գրադիենտային վայրէջքի միջոցով</li></a>
                <a href="chap1.html#implementing_our_network_to_classify_digits"><li>Թվանշանները ճանաչող ցանցի իրականացումը</li></a>
                <a href="chap1.html#toward_deep_learning"><li>Խորը ուսուցմանն ընդառաջ</li></a>
              </ul>
            </p>
          </div>
    <script>
      $('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() {
         var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
         if(src == 'images/arrow.png') {
           $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
         } else {
           $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
         };
         $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});
      });
    </script>
    <p class='toc_mainchapter'>
      <a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a>
      <a href="chap2.html">Ինչպե՞ս է աշխատում հետադարձ տարածումը</a>
      <div id="toc_how_the_backpropagation_algorithm_works" style="display: none;">
        <p class="toc_section">
          <ul>
            <a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
    _from_a_neural_network"><li>Մարզանք. նեյրոնային ցանցի ելքային արժեքների հաշվման արագագործ, մատրիցային մոտեցում</li></a>
            <a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>Երկու ենթադրություն գնային ֆունկցիայի վերաբերյալ</li></a>
            <a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>Հադամարի արտադրյալը՝ $s \odot t$</li></a>
            <a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>Հետադարձ տարածման հիմքում ընկած չորս հիմնական հավասարումները</li></a>
            <a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Չորս հիմնական հավասարումների ապացույցները (ընտրովի)</li></a>
            <a href="chap2.html#the_backpropagation_algorithm"><li>Հետադարձ տարածման ալգորիթմը</li></a>
            <a href="chap2.html#the_code_for_backpropagation"><li>Հետադարձ տարածման իրականացման կոդը</li></a>
            <a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>Ի՞նչ իմաստով է հետադարձ տարածումն արագագործ ալգորիթմ</li></a>
            <a href="chap2.html#backpropagation_the_big_picture"><li>Հետադարձ տարածում. ամբողջական պատկերը</li></a>
          </ul>
        </p>
      </div>

    <script>
      $('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() {
         var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
         if(src == 'images/arrow.png') {
           $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
         } else {
           $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
         };
         $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});
      });
    </script>
    <p class='toc_mainchapter'>
      <a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a>
      <a href="chap3.html">Նեյրոնային ցանցերի ուսուցման բարելավումը</a>
      <div id="toc_improving_the_way_neural_networks_learn" style="display: none;">
        <p class="toc_section">
          <ul>
            <a href="chap3.html#the_cross-entropy_cost_function"><li>Գնային ֆունկցիան՝ միջէնտրոպիայով</li></a>
            <a href="chap3.html#overfitting_and_regularization"><li>Գերմարզում և ռեգուլյարացում</li></a>
            <a href="chap3.html#weight_initialization"><li>Կշիռների սկզբնարժեքավորումը</li></a>
            <a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Ձեռագրերի ճամաչման կոդի վերանայում</li></a>
            <a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>Ինչպե՞ս ընտրել նեյրոնային ցանցերի հիպեր-պարամետրերը</li></a>
            <a href="chap3.html#other_techniques"><li>Այլ տեխնիկաներ</li></a>
          </ul>
        </p>
      </div>
        <script>
      $('#toc_improving_the_way_neural_networks_learn_reveal').click(function() {
         var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
         if(src == 'images/arrow.png') {
           $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
         } else {
           $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
         };
         $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});
      });
    </script>
        <p class='toc_mainchapter'>
      <a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a>
      <a href="chap4.html">Տեսողական ապացույց այն մասին, որ նեյրոնային ֆունկցիաները կարող են մոտարկել կամայական ֆունկցիա</a>
      <div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;">
        <p class="toc_section">
          <ul>
            <a href="chap4.html#two_caveats"><li>Երկու զգուշացում</li></a>
            <a href="chap4.html#universality_with_one_input_and_one_output"><li>Ունիվերսալություն մեկ մուտքով և մեկ ելքով</li></a>
            <a href="chap4.html#many_input_variables"><li>Մեկից ավել մուտքային փոփոխականներ</li></a>
            <a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Ընդլայնումը Սիգմոիդ նեյրոններից դուրս </li></a>
            <a href="chap4.html#fixing_up_the_step_functions"><li>Քայլի ֆունկցիայի ուղղումը</li></a>
            <a href="chap4.html#conclusion"><li>Եզրակացություն</li></a>
          </ul>
        </p>
      </div>
        <script>
      $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() {
         var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
         if(src == 'images/arrow.png') {
           $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
         } else {
           $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
         };
         $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});
      });
    </script>
    <p class='toc_mainchapter'>
      <a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a>
      <a href="chap5.html">Ինչու՞մն է կայանում նեյրոնային ցանցերի մարզման բարդությունը</a>
      <div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;">
        <p class="toc_section">
          <ul>
            <a href="chap5.html#the_vanishing_gradient_problem"><li>Անհետացող գրադիենտի խնդիրը</li></a>
            <a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>Ի՞նչն է անհետացող գրադիենտի խնդրի պատճառը։ Խորը նեյրոնային ցանցերի անկայուն գրադիենտները</li></a>
            <a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Անկայուն գրադիենտներն ավելի կոմպլեքս ցանցերում</li></a>
            <a href="chap5.html#other_obstacles_to_deep_learning"><li>Այլ խոչընդոտներ խորը ուսուցման մեջ</li></a>
          </ul>
        </p>
      </div>
    <script>
      $('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() {
         var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
         if(src == 'images/arrow.png') {
           $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
         } else {
           $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
         };
         $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});
      });
    </script>
    <p class='toc_mainchapter'>
      <a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a>
      <a href="chap6.html">Խորը ուսուցում</a>
      <div id="toc_deep_learning" style="display: none;">
        <p class="toc_section">
          <ul>
            <a href="chap6.html#introducing_convolutional_networks"><li>Փաթույթային ցանցեր</li></a>
            <a href="chap6.html#convolutional_neural_networks_in_practice"><li>Փաթույթային ցանցերը կիրառության մեջ</li></a>
            <a href="chap6.html#the_code_for_our_convolutional_networks"><li>Փաթույթային ցանցերի կոդը</li></a>
            <a href="chap6.html#recent_progress_in_image_recognition"><li>Առաջխաղացումները պատկերների ճանաչման ասպարեզում</li></a>
            <a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Այլ մոտեցումներ խորը նեյրոնային ցանցերի համար</li></a>
            <a href="chap6.html#on_the_future_of_neural_networks"><li>Նեյրոնային ցանցերի ապագայի մասին</li></a>
          </ul>
        </p>
      </div>
    <script>
    $('#toc_deep_learning_reveal').click(function() {
       var src = $('#toc_img_deep_learning').attr('src');
       if(src == 'images/arrow.png') {
         $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
       } else {
         $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
       };
       $('#toc_deep_learning').toggle('fast', function() {});
    });
    </script>
    <p class="toc_not_mainchapter">
      <a href="sai.html">Հավելված: Արդյո՞ք գոյություն ունի ինտելեկտի <em>պարզ</em> ալգորիթմ</a>
    </p>
    <p class="toc_not_mainchapter">
      <a href="acknowledgements.html">Երախտագիտություն</a>
    </p>
    <p class="toc_not_mainchapter"><a href="faq.html">Հաճախ տրվող հարցեր</a>
    </p>

<!--
<hr>

<p class="sidebar"> If you benefit from the book, please make a small
donation.  I suggest $3, but you can choose the amount.</p>

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="encrypted" value="-----BEGIN PKCS7-----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-----END PKCS7-----
">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

-->

<hr>
<span class="sidebar_title">Հովանավորներ</span>
<br/>
<a href='http://www.ersatz1.com/'><img src='assets/ersatz.png' width='140px' style="padding: 0px 0px 10px 8px; border-style: none;"></a>

<a href='http://gsquaredcapital.com/'><img src='assets/gsquared.png' width='150px' style="padding: 0px 0px 10px 10px; border-style: none;"></a>

<a href='http://www.tineye.com'><img src='assets/tineye.png' width='150px'
style="padding: 0px 0px 10px 8px; border-style: none;"></a>

<a href='http://www.visionsmarts.com'><img
src='assets/visionsmarts.png' width='160px' style="padding: 0px 0px
0px 0px; border-style: none;"></a> <br/>

<p class="sidebar">Շնորհակալություն եմ հայտնում բոլոր <a
href="supporters.html">աջակցողներին</a>, ովքեր օգնել են գիրքն իրականություն դարձնել:
Հատուկ շնորհակալություններ Պավել Դուդրենովին. Շնորհակալություն եմ հայտնում նաև նրանց,
ովքեր ներդրում են ունեցել <a href="bugfinder.html">Սխալների որոնման հուշատախտակում</a>.  </p>

<hr>
<span class="sidebar_title">Ռեսուրսներ</span>

<p class="sidebar"><a href="https://twitter.com/michael_nielsen">Մայքլ Նիլսենը թվիթերում</a></p>

<p class="sidebar"><a href="faq.html">Գրքի մասին հաճախակի տրբող հարցեր</a></p>

<p class="sidebar">
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning">Կոդի պահոցը</a></p>

<p class="sidebar">
<a href="http://eepurl.com/0Xxjb">Մայքլ Նիլսենի նախագծերի հայտարարման էլ հասցեների ցուցակը</a>
</p>

<p class="sidebar"> <a href="http://www.deeplearningbook.org/">Խորը Ուսուցում</a>, գրքի հեղինակներ` Յան Գուդֆելլո, Յոշուա Բենջիո և Ահարոն Կուրվիլ</p>

<p class="sidebar"><a href="http://cognitivemedium.com">cognitivemedium.com</a></p>

<hr>
<a href="http://michaelnielsen.org"><img src="assets/Michael_Nielsen_Web_Small.jpg" width="160px" style="border-style: none;"/></a>

<p class="sidebar">
<a href="http://michaelnielsen.org">Մայքլ Նիլսեն</a>, Հունվար 2017
</p>
</div>

<p>Մարդկային տեսողական համակարգը աշխարհի հրաշալիքներից է:Դիտարկենք ձեռագիր թվանշանների հետևյալ հերթականությունը: <a name="complete_zero"></a></p><p><center><img src="images/digits.png" width="160px"></center> </p><p>  Մարդկանց մեծամասնությունը առանց ջանք գործադրելու կարող է ճանաչել 504192 թվերը: Այդ դյուրինությունը խաբուսիկ է սակայն: Մարդկային ուղեղի կիսագնդերում պարունակվում է հիմնական տեսողական կորտեքսը, որը հայտնի է որպես V1: Այն պարունակում է 140 միլիոն նեյրոններ, որոնք իրար հետ կապված են տասնյակ միլիարդավոր կապերով: Ընդ որում, մարդկային տեսողությունը բաղկացած չէ միայն V1-ից, այլ V2, V3, V4, և V5 տեսողական կորտեքսներից, որոնք իրականացնում են բազմաթիվ նկարների մշակում:  Մեր գլուխներն ըստ էության պարունակում են սուպեր համակարգիչներ` էվոլյուցիայի միջոցով կատարելագործված միլիոնավոր տարիների ընթացքում և հրաշալիորեն հարմարված տեսանելի աշխարհը հասկանալու համար: Ձեռագիր թվանշանները հասկանալը հեշտ չէ, այնուամենայնիվ, մարկանց մոտ լավ է ստացվում հասկանալ այն ինչ իրենց աչքերն են ընկալում: Սակայն գրեթե ամբողջ այդ աշխատանքը կատարվում է ենթագիտակցորեն, հետևաբար մենք ըստ արժանվույն չենք գնահատում թե ինչպիսի դժվար խնդիր է լուծում տեսողական համակարգը:</p><p>  Տեսողական համակարգի օրինաչափությունը հասկանալու դժվարությունը երևան է գալիս այն ժամանակ, երբ փորձ է  արվում ստեղծել ծրագիր ձեռագիր թվանշաններ ճանաչելու համար: Մեզ հեշտ թվացող այդ երևույթը  պարզվում է, որ բավականին բարդ է: Պատկերներ ճանաչելու պարզ ինտուիցիան (օրինակ, 9 թվանշանը վերևում  շրջանաձև է, որը կապվում է նրեքևի հետ կոր ուղղաձիգով) պարզվում է որ այնքան էլ պարզ չէ, թե ինչպես նկարագրել  ալգորիթմորեն: Երբ փորձ է կատարվում նպանատիպ կանոնները հստակեցնելու, անմիջապես խճճվում ենք բացառությունների  կամ հատուկ դեպքերի կծիկի մեջ: Արագորեն հուսալքվում ենք խնդրի լուծման հարցում:</p><p></p><p>  Նեյրոնային ցանցերը խնդրին մոտենում են այլ կերպ: Միտքը կայանում է նրանում, որ  պետք է վերցնել մեծ քանակությամբ ձեռագիր թվանշաններ, որոնց կանվանենք մարզման օրինակներ,</p><p>  <center><img src="images/mnist_100_digits.png" width="440px"></center></p><p>  և կառուցել այնպիսի համակարգ, որը կարող է սովորել այդ օրինակներից: Այլ կերպ ասած, նեյրոնային  ցանցը օգտագործում է օրինակները ձեռագիր թվանշանների կառուցվածքն ինքնաբերաբար  հասկանալու համար: Ավելին, շատացնելով օրինակների քանակը, ցանցը կարող է ավելի շատ  ուսուցանել ձեռագրերի մասին, այսպիսով բարելավելով գուշակման ճշգրտությունը: Օրինակ, ցանցը ավելի ճշգրիտ  կարող է գուշակել սովորելով 1000 օրինակի վրա քան 100 օրինակի:</p><p>  Այս գլխում կկառուցենք համակարգչային ծրագիր, որը իրականացնում է նեյրոնային ցանց,  որն իր հերթին սովորում է ճանաչել ձեռագիր թվանշանները: Ծրագիրը ունի 74 տող երկարություն  և չի օգտագործում ոչ մի նեյրոնային ցանցերի գրադարան: Սակայն այն կարող է թվանշանները  ճանաչել 96 տոկոս ճշտությամբ առանց մարդկային միջամտության: Այնուհետև հետագա  գլուխներում կկառուցենք գաղափարներ, որոնք կօգնեն ճանաչման ճշտությունը հասցնել  99 տոկոսից ավելիին: Փաստացիորեն, լավագույն կոմերցիոն նեյրոնային ցանցերն այնքան  հուսալի են, որ օգտագործվում են բանկերի կողմից չեկերի մշակման համար, փոստատների  կողմից հասցեների ճանաչման համար:</p><p>  Մենք կենտրոնանում ենք ձեռագիր թվանշանների ճանաչման վրա, քանի որ այն  նեյրոնային ցանցերի մասին սովորելու համար գերազանց նախատիպային խնդիր է:  Որպես նախատիպային խնդիր ըստ երևույթին այն հեշտ չէ, սակայն այնքան բարդ չէ որ կարիք զգացվի  չափազանց բարդ լուծման տեխնիկաների կամ համակարգչային հզորության (computational power) օգտագործման:  Հետևաբար սա հրաշալի մոտեցում է ավելի առաջադեմ տեխնիկաների հմտություններ յուրացնելու հարցում,  օրինակ խորը ուսուցումը: Այսպիսով, գրքում պարբերաբար վերադառնալու ենք ձեռագիր թվանշանների  ճանաչման խնդրին: Ավելի ուշ նաև կքննարկենք թե ինչպես կարելի է օգտագործել այս  գաղափարները այլ խնդիրների լուծման համար, օրինակ` համակարգչային տեսողության (computer vision),  բնական լեզվի ճանաչում (speech, natural language processing) և այլն:</p><p>  Իհարկե, եթե այս գլխի նպատակը լիներ միայն ձեռագիր թվանշաններ ճանաչող ծրագրի կառուցումը,  ապա գլուխն ավելի քիչ ծավալուն կլիներ: Մենք խոսելու ենք նաև նեյրոնային ցանցերի մասին այլ կարևոր գաղափարներից,  հատկապես երկու կարևոր արհեստական նեյրոնների տեսակների մասին՝ պերսեպտրոն և սիգմոիդ նեյրոն, ինչպես նաև նեյրոնային  ցանցերի ստանդարտ ուսուցման ալգորիթմի մասին, որը հայտնի է որպես ստոկաստիկ գրադիենտային վայէջք (stochastic  gradient descent): Ավելի խորը հասկանալու համար առկա են նաև քննարկումներ այն մասին, թե ինչպես կարելի է  ինտուցիա կառուցել և կարողանալ հասկանալ նեյրոնային ցանցերի ներքին աշխատանքը:</p><p>  <h3><a name="perceptrons"></a><a href="#perceptrons">Պերսեպտրոններ</a></h3></p><p>  Ի՞նչ է նեյրոնային ցանցը: Սկզբում կդիտարկենք արհեստական նեյրոնի մի տարատեսակ, որ կոչվում է <em>պերսեպտրոն</em>:  Պերսեպտրոնները <a href="http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ">ստեղծվել են</a>  1950-1960-ականներին <a href="http://en.wikipedia.org/wiki/Frank_Rosenblatt">Ֆրանկ Ռոզենբլատի կողմից</a>՝  ոգեշնչված <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Ուորեն ՄակԿուլոքի</a> և  <a href="http://en.wikipedia.org/wiki/Walter_Pitts">Վալտեր Փիթսի</a> ավելի վաղ կատարված  <a href="http://scholar.google.ca/scholar?cluster=4035975255085082870">աշխատանքով</a>:  Այսօր ավելի հաճախ օգտագործում են արհեստական նեյրոնների այլ մոդելներ․ այս գրքում և նեյրոնային ցանցերի  վերաբերյալ ժամանակակից աշխատանքների մեծամասնության մեջ օգտագործվող նեյրոնների հիմնական մոդելը կոչվում  է <em>սիգմոիդ նեյրոն</em>: Մենք շուտով կանդրադառնանք սիգմոիդ նեյրոններին: Բայց որպեսզի հասկանանք, թե  ինչու են սիգմոիդ նեյրոնները սահմանվում այնպես, ինչպես սահմանվում են, արժե նախ ժամանակ ծախսել պերսեպտրոնները  հասկանալու համար:</p><p>Ինչպե՞ս են աշխատում պերսեպտրոնները:  Պերսեպտրոնը մուտքում ստանում է մի քանի  երկուական արժեքներ, $x_1, x_2, \ldots$, և ելքում ստանում է մեկ երկուական արժեք (որպես ելք նշանակենք output,  այսուհետ այս երկու տերմինները կօգտագործվեն փոխարինաբար)․  <center>  <img src="images/tikz0.png"/>  </center>  Այս օրինակում պերսեպտրոնը ունի երեք մուտքեր, $x_1, x_2, x_3$:  Ընդհանուր դեպքում այն կարող է ունենալ ավելի շատ կամ ավելի քիչ մուտքեր: Ռոզենբլատը առաջարկել է ելքում ստացվող արժեքը հաշվարկելու պարզ կանոն: Նա ներմուծեց <em>կշիռներ</em>, $w_1,w_2,\ldots$, իրական թվեր, որոնք արտահայտում են համապատասխան մուտքերի կարևորությունը ելքի համար: Նեյրոնի ելքը, $0$ կամ $1$, որոշվում է կախված այն բանից, թե $\sum_j w_j x_j$ կշռված գումարը փոքր է, թե մեծ է որոշակի <em>շեմային արժեքից</em>: Շեմը, ինչպես կշիռները, իրական թիվ է, որը հանդիսանում է նեյրոնի պարամետր:  Ավելի ճշգրիտ հանրահաշվական տերմիններով`  <a class="displaced_anchor" name="eqtn1"></a>\begin{eqnarray}  \mbox{ելք} & = & \left\{ \begin{array}{ll}  0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ շեմ} \\  1 & \mbox{if } \sum_j w_j x_j > \mbox{ շեմ}  \end{array} \right.  \tag{1}\end{eqnarray}  Այսքանն է պերսեպտրոնի աշխատանքի նկարագրությունը:</p><p>  Սա պարզագույն մաթեմատիկական մոդելն է: Դուք կարող եք պերսեպտրոնը հասկանալ որպես մի մեխանիզմ կամ սարք,  որը փաստերը կշռելով կայացնում է որոշումներ: Քննարկենք մի օրինակ: Օրինակը այնքան էլ իրատեսական չէ,  սակայն հեշտ է հասկանալը, և մենք շուտով կդիտարկենք ավելի իրատեսական օրինակներ:  Ենթադրենք մոտենում են հանգստյան օրերը և դուք լսել եք, թե ձեր քաղաքում կայանալու է պանրի փառատոն:  Դուք պանիր սիրում եք և խնդիր ունեք որոշելու արդյոք արժի գնալ փառատոնին: Որոշօւմը կայացնում եք հիմնվելով  երեք գործոնների վրա․  <ol>    <li> Արդյո՞ք եղանակը լավն է,    <li> Արդյո՞ք ձեր ընկերը կամ ընկերուհին ցանկություն ունեն միանալ ձեզ,    <li> Արդյո՞ք հնարավոր է փառատոնին հասնել հասարակական տրանսպորտով (ենթադրենք, որ դուք չունեք ավտոմեքենա):  </ol>  Կարող ենք այս երեք գործոնները ներկայացնել $x_1, x_2$ և $x_3$ երկուական փոփոխականներով:  Օրինակ, եթե եղանակը լավն է, ապա ունենք $x_1 = 1$,  իսկ եթե եղանակը բարենպաստ չէ, ապա $x_1 = 0$: Նմանապես, $x_2 = 1$ եթե  ձեր ընկերը կամ ընկերուհին ցանկություն ունեն գնալու, և $x_2 = 0$ հակառակ դեպքում:  Նույն ձևով որոշվում է $x_3$-ի հասարակական տրանսպորտի հետ կապված:</p><p>  Այժմ ենթադրենք որ դուք պանիր շատ եք սիրում, ընդ որում այնքան շատ, որ պարաստ եք գնալ փառատոնին  նույնիսկ եթե ձեր ընկերը կամ ընկերուհին հետաքրքրված չեն և փառատոնին հասնելը դժվար է: Բայց  գուցե դուք տանել չեք կարողանում վատ եղանակը և հաստատ չեք մասնակցի փառատոնին, եթե  եղանակը անբարենպաստ լինի: Այս բնույթի որոշում կայացնելը մոդելավորելու համար կարող եք  օգտագործել պերսեպտրոն: Օրինակ, կարելի է եղանակի համար կշիռը վերցնել որպես $w_1 = 6$, իսկ մյուս  պայմանների համար՝ համապատասխանաբար $w_2 = 2$ և $w_3 = 2$: $w_1$-ի մեծ արժեքը ցույց է տալիս, որ եղանակը շատ  կարևոր է ձեզ համար՝ շատ ավելի կարևոր է, քան այն փաստը, որ ձեր ընկերը կամ ընկերուհին կմիանան ձեզ  կամ հասարակական տրանսպորտի հարմարությունը: Վերջապես, ենթադրենք, որ դուք որպես պերսեպտրոնի շեմ ընտրում  եք 5-ը: Շեմի այսպիսի արժեքի դեպքում պերսեպտրոնը կմոդելավորի ձեր որոշում կայացնելու խնդիրը՝  ելքում տալով 1, եթե եղանակը լավն է, և 0, եթե եղանակը բարենպաստ չէ: Հարկ է նկատել, որ վերևում  նկարագրած մոդելի դեպքում ձեր ընկերոջ կամ ընկերուհու մասնակցելու ցանկությունը կամ հասարակական  տրանսպորտի հարմարությունը «որոշման» ելքի վրա Էապես չեն ազդի:</p><p>  Կշիռները և շեմը փոփոխելով՝ կստանանք որոշման կայացման տարբեր մոդելներ: Օրինակ, որպես շեմ ընտրենք  $3$-ը: Այդ դեպքում պերսեպտրոնը «կորոշի», որ դուք փառատոնին գնաք այն ժամանակ, երբ եղանակը բարենպաստ է  <em>կամ</em> երբ փառատոնը մոտ է հասարակական տրանսպորտին <em>և</em> ձեր ընկերը կամ ընկերուհին  պատրաստ են միանալ ձեզ: Մի խոսքով դա կդառնա որոշում կայացնելու ուրիշ մոդել: Շեմն իջեցնելը նշանակում է  որ դուք ընդհանուր առմամբ հակված եք փառատոնին մասնակցելուն:</p><p>  Պարզ է, որ պերսեպտրոնը մարդկային որոշում կայացնելու ամբողջական մոդել չէ: Սակայն օրինակը ցույց տվեց թե  ինչպես այն կարող է համեմատել տարատեսակ գործոնները որոշում կայացնելու նպատակով: Ավելին, կարծես իրականալի  է թվում այն, որ պերսեպտրոնների բարդ կառուցվածքը կարող է անգամ իրականացնել ոչ պարզ որոշումներ:  <center>    <img src="images/tikz1.png"/>  </center>  Հետևյալ ցանցում պերսեպտրոնների առաջին սյունակը, որին կանվանենք պերսեպտրոնների առաջին <em>շերտ</em>,  իրականացնում է 3 պարզ որոշումներ` համեմատելով տրված գործոնները: Իսկ ի՞նչ կարելի է ասել 2-րդ շերտի  պերսեպտրոնների մասին: Այդ պերսեպտրոններից յուդաքանչյուրը որոշում է կայացնում համեմատելով առաջին շերտի  կայացրած որոշումների արդյունքները: Այդ կերպ երկրորդ շերտի պերսեպտրոնը կարող է կայացնել ավելի բարդ և  աբստրակտ մակարդակի որոշումներ քան առաջին շերտի պերսեպտրոնները: Երրորդ շերտի պերսեպտրոնները կարող են  կայացնել անգամ ավելի բարդ որոշումներ: Այս ձևով բազմաշերտ պերսեպտրոնների ցանցը կարող է կայացնել բավականին  բարդ որոշումներ:</p><p>  Ի դեպ, պերսեպտրոնի սահմանման մեջ նշել էինք, որ նրանք ունեն մեկ  ելքային արժեք: Կարող է տպավորություն ստեղծվել, որ վերևում նկարված ցանցում պերսեպտրոններն  ունեն մեկից ավելի ելքեր: Իրականում, մեկից ավել նկարված ելքային սլաքներն ուղղակի  նշանակում են, որ տվյալ պերսեպտրոնի ելքը հանդիսանում է մուտք բազմաթիվ այլ պերսեպտրոնների:  Այսպիսի նշանակումն ավելի հարմար է դարձնում ցանց նկարելն ու պատկերացնելը:</p><p>  Փորձենք պարզեցնել պերսեպտրոնի նկարագրությունը: $\sum_j w_j x_j > \mbox{շեմ}$ պայմանը  կարելի է պարզեցնել՝ կատարելով երկու փոփոխություն: Առաջին փոփոխությունն է` ներկայացնենք $\sum_j w_j x_j$ գումարը որպես  $w \cdot x \equiv \sum_j w_j x_j$ վեկտորների սկալյար արտադրյալ, որտեղ $w$-ն կշիռների վեկտորն է,  $x$-ը` մուտքային: Երկրորդ փոփոխությունն է` տանել ելքը անհավասարման մյուս մասը և վերանվանել այն  որպես պերսեպտրոնի <em>շեղում</em>` $b \equiv -\mbox{շեմ}$: Օգտագործելով շեղումը շեմի փոխարեն,  պերսեպտրոնը կգրենք.  <a class="displaced_anchor" name="eqtn2"></a>  \begin{eqnarray}    \mbox{ելք} = \left\{      \begin{array}{ll}        0 & \mbox{if } w\cdot x + b \leq 0 \\        1 & \mbox{if } w\cdot x + b > 0      \end{array}    \right.  \tag{2}\end{eqnarray}  Շեղումը կարելի է հասկանալ որպես մի մեծություն, որը ցույց է տալիս, թե ինչ հեշտությամբ կարելի է այնպես անել,  որ պերսեպտրոնը ելքում ստանա $1$ արժեքը կամ կենսաբանորեն՝ շեղումը ցույց է  տալիս թե որքան հեշտությամբ կարելի է այնպես անել, որ պերսեպտրոնը <em>հրահանգի</em>:  Մեծ շեղումների դեպքում պերսեպտրոնը ելքում $1$ արժեքն ավելի դյուրին է ստանում, քան փոքր շեղումների դեպքում:  Պարզ է, որ շեղումը չնչին փոփոխություն է պերսեպտրոնների նկարագրության մեջ, սակայն ավելի ուշ կհամոզվենք,  որ դա կբերի էական պարզեցումների: Այդ իսկ պատճառով, այսուհետ կօգտագործենք շեղում տերմինը շեմի փոխարեն:</p><p>  Պերսեպտրոնները նկարագրել ենք որպես վկայությունների կշռման մեթոդ, որի միջոցով  կարելի է կատարել որոշումներ: Սակայն պերսեպտրոնը կարելի է օգտագործել  պարզագույն հաշվողական այնպիսի միավորների կառուցման համար, ինչպիսիք են <CODE>AND</CODE>, <CODE>OR</CODE>  և <CODE>NAND</CODE> գործողությունները: Օրինակ, ենթադրենք, որ ունենք պերսեպտրոն երկու  մուտքերով, ամենքի արժեքը` $-2$, իսկ շեղումը $3$ է: Ահա մեր պերսեպրտոնը.  <center>    <img src="images/tikz2.png"/>  </center>  Հեշտ է նկատել, որ $00$ մուտքից ստացվում է $1$ ելքային արժեքը, քանի որ $(-2)*0+(-2)*0+3 = 3$  դրական է: $*$ սիմվոլի օգտագործումը նախատեսված է բազմապատկումն ավելի ակնառու դարձնելու համար:  Նույն ձևով հեշտ է համոզվել, որ $01$ և $10$ մուտքերի դեպքում արժեքը $1$ է: Սակայն  $11$ մուտքի դեպքում արժեքը $0$ է, քանի որ $(-2)*1+(-2)*1+3 = -1$ բացասական է: Այսպիսով,  նկատենք, որ մեր պերսեպտրոնը մոդելավորում է <CODE>NAND</CODE> գործողությունը:</p><p><a name="universality"></a></p><p>  <CODE>NAND</CODE>-ի օրինակը ցույց է տալիս, որ կարող ենք հասշվել պարզ տրամաբանական  ֆունկցիաներ: Իրականում պերսեպտրոնների ցանցի միջոցով կարելի է հաշվել <em>կամայական</em> տրամաբանական  ֆունկցիա, քանի որ <CODE>NAND</CODE>-ը ունիվերսալ հաշվողական միավոր է, որով կարելի է կառուցել մնացած  գործողությունները: Օրինակ, <CODE>NAND</CODE>-ը կարող ենք օգտագործել գումարման սխեմա կառուցելու համար,  որը գումարում է $x_1$ և $x_2$ բիթերը: Սա նշանակում է հաշվել $x_1 \oplus x_2$ բիթ առ բիթ գումարումը և  մնացորդային բիթը, որը $1$ է, երբ $x_1$ և $x_2$ բիթերը $1$ են և 0` մնացած դեպքերում:  <center>   <img src="images/tikz3.png"/>  </center>  Համարժեք պերսեպտրոնների ցանց ստանալու համար, բոլոր <CODE>NAND</CODE>-երը  փոխարինենք երկումուտքանի պերսեպտրոններով, յուրաքանչյուրը $-2$ կշռով և $3$ շեղումով:  Ահա թե ինչ ցանց է ստացվում: Նկատենք, որ աջ ներքևի <CODE>NAND</CODE> գործողությանը  համապատասխանող գագաթը տեղաշարժված է նկարելն ավելի հեշտացնելու նպատակով:  <center>    <img src="images/tikz4.png"/>  </center>  Նկատենք, որ ձախակողմյան մասում գտնվող պերսեպտրոնի ելքերը հանդիսանում են մուտքեր  ամենաներքևում գտնվող պերսեպտրոնի համար: Պերսեպտրոնի սահմանման մեջ նշված չէր,  որ այսպիսի նկարագրություն թույլատրելի է, սակայն դա ոչ մի նշանակություն չունի: Եթե  որոշում ենք թույլ չտալ նմանատիպ նշանակումներ, ապա կարող ենք միացնել երկու գծերը  և դարձնել այն մեկ կապ -4 կշռով՝ երկու -2 կշռով կապերի փոխարեն: (Եթե այս մասը ակնհայտ չեք  համարում, ապա խորհուրդ եմ տալիս կանգ առնել և համոզվել որ սա համարժեք է): Այդ  փոփոխությունից հետո ցանցի տեսքը կլինի այսպիսի (բոլոր չնշված կշիռները -2, բոլոր շեղումները  3 և վերոնշյալ կապը -4 կշռով, ինչպես նշված է)  <center>   <img src="images/tikz5.png"/>  </center>  Նպատակահարմար է նաև վերցնել $x_1$ և $x_2$ մուտքային արժեքները որպես մուտքային պերսեպտրոնների  <em>շերտ</em>.  <center>   <img src="images/tikz6.png"/>  </center>  Օգտագործենք հետևյալ նշանակումն այն պերսեպտրոնների համար, ովքեր ունեն ելք բայց  չունեն մուտք.  <center>    <img src="images/tikz7.png"/>  </center></p><p>  Գումարման գործողության իրականացումը ցույց է տալիս, թե ինչպես կարելի է, օգտագործելով  պերսեպտրոնները, բազմաթիվ <CODE>NAND</CODE> գործողություններ պարունակող սխեմա  սիմուլացնել: Եվ քանի որ <CODE>NAND</CODE>-երը ունիվերսալ հաշվարկային միավորներ են,  ապա հետևում է, որ նույնը ճիշտ է նաև պերսեպտրոնների համար:</p><p>  Պերսեպտրոնների ունիվրսալ հաշվողունակությունը միժամանակ և՛ հուսադրող է, և՛ հիասթափեցնող:  Այն հուսադրող է, քանի որ այն ցույց է տալիս, որ պերսեպտրոնների ցանցը կարող է կամայակն այլ  հաշվողական սարքին հավասարաչափ հզոր լինել: Սակայն դա նույնքան հիասթափեցնող է, քանի որ մյուս  կողմից էլ ստացվում է, որ պերսեպտրոնները պարզապես <CODE>NAND</CODE>-ի նոր տեսակ են: Դա  այդքան էլ մեծ նորություն չէ:</p><p>  Այնուամենայնիվ, իրավիճակը շատ ավելի բարվոք է: Պարզվում է, որ հնարավոր է դուրս բերել  <em>սովորող ալգորիթմներ</em>, որոնք ինքնաբերաբար կարող են ձևափոխել արհեստական նեյրոնների  կշիռներն ու շեղումները: Այսպիսի ձևափոխումը տեղի է ունենում ի պատասխան արտաքին գործոնների,  այլ ոչ ծրագրավորողի նախապես պլանավորված ալգորիթմի հաշվին: Սովորող ալգորիթմները թույլ են  տալիս մեզ օգտագործել արհեստական նեյրոնները  էապես տարբեր ձևով, քան արդեն ընդունված տրամաբանական գործողություններն են: Ուղղակիորեն  <CODE>NAND</CODE> գործողությունների հերթականություն մշակելու փոխարեն, նեյրոնային ցանցը պարզապես  սովորում է լուծել խնդիրներ, երբեմն խնդիրներ, որոնց լուծելու համար ավանդական սխեմա կառուցելը շատ ավելի  բարդ կլիներ:</p><p>  <h3>    <a name="sigmoid_neurons"></a>    <a href="#sigmoid_neurons">Սիգմոիդ Նեյրոններ</a>  </h3></p><p>  Սովորող ալգորիթմները գաղափարն իհարկե հրաշալի է հնչում: Բայց ինչպե՞ս կարող ենք դուրս  բերել նմանատիպ ալգորիթմներ նեյրոնային ցանցերի համար: Ենթադրենք ունենք պերսեպտրոնների  ցանց, որը կուզենայինք օգտագործել որոշակի խնդիր լուծելու նպատակով: Օրինակ,  որպես մուտքային տվյալներ կարող են հանդիսանալ ձեռագիր թվանշանի թվային ձևաչափով պատկերի պիքսելները:  Ընդ որում մեր նպատակն է, որ ցանցը սովորի կշիռներն ու շեղումները այնպես, որ ելքում  ստանանք թվանշանների դասակարգումը: Որպեսզի հասկանանք, թե ինչպես կարող է ուսուցումն  աշխատել, ենթադրենք, որ ցանցում կշռի կամ շեղման մեջ կատարել ենք փոքրիկ փոփոխություն:  Այս փորձի նախընտրելի արդյունքն այն կլիներ, որ այդ փոքր փոփոխությունը հանգեցներ  փոկր փոփոխության ցանցի ելքում: Ինչպես շուտով կհամոզվենք, դա է այն հատկությունը, որն ուսուցումը  հնարավոր է դարձնում: Սխեմատիկորեն, ահա այն է ինչ անհրաժեշտ է մեզ (ակնհայտ է, որ այս ցանցը  չափազանց պարզ է ձեռագիր թվանշաններ ճանաչելու համար).</p><p>  <center>    <img src="images/tikz8.png"/>  </center></p><p>  Եթե կշռի կամ շեղման փոքր փոփոխության հետևանքով ելքում փոքր փոփոխություն առաջանար,  ապա մենք կկարողանայինք օգտագործել այդ փաստը կշիռներն ու շեղումները  փոփոխելու համար այնպես, որ ցանցը ստանար մեզ համար ցանկալի վարքագիծ: Օրինակ,  ենթադրենք ցանցը "9" սխալմամբ թվանշանը ճանաչում է որպես "8": Մենք կարող ենք  շեղման և կշիռների համար գտնել մի այնպիսի փոփոխություն, որ ցանցը փոքր ինչ ավելի  մոտենա թվանշանը որպես "9" ճանաչելուն: Այնուհետև կարող ենք կրկնել այս քայլը այնքան  մինչև ստանանք ավելի և ավելի նպատակահարմար ելքեր: Այսպիսով կասենք, որ ցանցը ուսուցանում է</p><p>  Խնդիրը կայանում է նրանում, որ վերևում նկարագրվածը պերսեպտրոնների դեպքում տեղի չի ունենում:  Իրականում, երբեմն մեկ պերսեպտրոնի կշիռների և շեղման չնչին փոփոխությունը կարող է  հանգեցնել ելքի կտրուկ փոփոխության՝ $0$-ից $1$: Այս փոփոխությունը կարող է  հանգեցնել ցանցի մնացած հատվածներում բավականին կոմպլեքս փոփոխություններ: Այսպիսով,  անգամ եթե 9 ճշտորեն ճանաչվի, ապա վարքագիծը այլ մուտքերի դեպքում կարող է անկառավարելիորեն  փոխվել: Այդ իսկ պատճառով կշիռների և շեղման փոքրիկ փոփոխությամբ ցանցի վարքագիծը փոխելով  նպատակին մոտենալը դառնում է բավականին գրեթե անհնար: Կարող է այս խնդիրը շրջանցելու  խելացի միջոց գոյություն ունի, սակայն միանգամից ակնհայտ չէ, թե ինչպես կարող ենք սովորեցնել  պերսեպտրոնների ցանցին:</p><p>  Մենք կարող ենք շրջանցել այս խնդիրը՝ ներմուծելով նոր տեսակի արհեստական նեյրոն,  որը կոչվում է <em>սիգմոիդ</em> նեյրոն: Սիգմոիդ նեյրոնները նման են պերսոտրոններին,  սակայն փոփոխված են այնպես, որ կշռի կամ շեղման փոքր փոփոխություններիը առաջացնում են  փոքր փոփոխություններ ելքում: Սա է այն պայմանը, որի դեպքում սիգմոիդ նեյրոնների ցանցը կկարողանա  սովորել:</p><p>  Նկարագրենք սիգմոիդ նեյրոնը: Կպատկերենք այն այնպես ինչպես պատկերել էինք պերսեպտրոնը.  <center>    <img src="images/tikz9.png"/>  </center>  Ինչպես պերսեպտրոնը, սիգմոիդը նույնպես ունի $x_1, x_2, \ldots$. մուտքեր: Սակայն $0$ կամ $1$-ի
  փոխարեն նրանք կարող են ընդունել $0$-ի և $1$-ի միջև կամայական արժեք: Օրինակ, $0.638\ldots$-ը
  ընդունելի աժեք է մուտքի համար: Ինչպես պերսեպտրոնը, սիգմոիդ նեյրոններն ունեն կշիռներ $w_1, w_2, \ldots$  և շեղում $b$: Սակայն ելքը $0$ կամ $1$-ի փոխարեն $\sigma(w \cdot x+b)$ է, որտեղ $\sigma$ ֆունկցիան կոչվում է  <em>սիգմոիդ</em>*    <span class="marginnote">      *Ի դեպ, $\sigma$-ն երբեմն կոչվում է <em>լոգիստիկ ֆունկցիա(logistic function)</em>, և հետևաբար,      նեյրոնների այս նոր տիպը` <em>լոգիստիկ նեյրոններ(logistic neurons)</em>: Հետևյալ տերմինները նույնպես      հաճախ օգտագործվող են, հետևաբար արժե տեղեկացված լինել այլ անվանումների մասին։
      Այնուամենայնիվ, այս գրքում մենք կօգտագործենք սիգմոիդ անվանումը:
    </span>:  և սահմանվում է.  <a class="displaced_anchor" name="eqtn3"></a>  \begin{eqnarray}    \sigma(z) \equiv \frac{1}{1+e^{-z}}.    \tag{3}  \end{eqnarray}  Այսպիսով, սիգմոիդ նեյրոնի ելքը $x_1,x_2,\ldots$ մուտքերի, $w_1,w_2,\ldots$ կշիռների  և $b$ շեղման դեպքում կլինի.
  <a class="displaced_anchor" name="eqtn4"></a>  \begin{eqnarray}    \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.    \tag{4}  \end{eqnarray}</p><p>  Սիգմոիդ նեյրոնները կարող են առաջին հայացքից տարբեր թվալ պերսեպտրոններից:
  Իսկ եթե ծանոթ չեք ֆունկցիայի հետ, ապա սիգմոիդի տեսքը կարող է նաև ակնհայտ չլինել: Իրականում,
  պերսեպտրոնների և սիգմոիդ նեյրոնների միջև կան բազմաթիվ նմանություններ:</p><p>  Որպեսզի հասկանանք այդ նմանությունները, ենթադրենք $z$-ը բավականին մեծ դրական թիվ է՝ ներկայացված հետևյալ տեսքով`
  $z \equiv w \cdot x + b$: Հետևաբար, $e^{-z} \approx 0$ և $\sigma(z) \approx 1$:  Այլ կերպ ասած, եթե $z = w \cdot x+b$ մեծ դրական թիվ է, ապա սիգմոիդ նեյրոնի արժեքը մոտավոր $1$ է
  (այնպես, ինչպես կլիներ պերսեպտրոնի դեպքում): Մյուս կողմից, ենթադրենք, որ $z = w \cdot x+b$ շատ փոքր
  բացասական թիվ է, ապա $e^{-z} \rightarrow \infty$ և $\sigma(z) \approx 0$, հետևաբար, եթե  $z = w \cdot x +b$ շատ փոքր բացասական թիվ է, ապա սիգմոիդի արժեքը ձգտում է պերսեպտրոնի արժեքին:  Միայն $w \cdot x+b$-ի ոչ մեծ բացարձակ արժեքների դեպքում է, որ սիգմոիդի և պերսեպտրոնի մոդելները տարբերվում են:
</p><p>  Իսկ ի՞նչ տեսք ունի $\sigma$-ն: Ինչպե՞ս հասկանանք այն: Իրականում $\sigma$-ի ճշգրիտ արժեքն էական չէ, էական է  այն, թե ինչ տեսք ունի ֆունկցիայի գրաֆիկը: Ահա այն.</p><p>  <div id="sigmoid_graph"><a name="sigmoid_graph"></a></div>  <script src="https://d3js.org/d3.v3.min.js"></script>  <script>    function s(x) {return 1/(1+Math.exp(-x));}    var m = [40, 120, 50, 120];    var height = 290 - m[0] - m[2];    var width = 600 - m[1] - m[3];    var xmin = -5;    var xmax = 5;    var sample = 400;    var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);    var data = d3.range(sample).map(function(d){ return {            x: x1(d),            y: s(x1(d))};        });    var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);    var y = d3.scale.linear()                    .domain([0, 1])                    .range([height, 0]);    var line = d3.svg.line()        .x(function(d) { return x(d.x); })        .y(function(d) { return y(d.y); })    var graph = d3.select("#sigmoid_graph")        .append("svg")        .attr("width", width + m[1] + m[3])        .attr("height", height + m[0] + m[2])        .append("g")        .attr("transform", "translate(" + m[3] + "," + m[0] + ")");    var xAxis = d3.svg.axis()                      .scale(x)                      .tickValues(d3.range(-4, 5, 1))                      .orient("bottom")    graph.append("g")        .attr("class", "x axis")        .attr("transform", "translate(0, " + height + ")")        .call(xAxis);    var yAxis = d3.svg.axis()                      .scale(y)                      .tickValues(d3.range(0, 1.01, 0.2))                      .orient("left")                      .ticks(5)    graph.append("g")        .attr("class", "y axis")        .call(yAxis);    graph.append("path").attr("d", line(data));    graph.append("text")         .attr("class", "x label")         .attr("text-anchor", "end")         .attr("x", width/2)         .attr("y", height+35)         .text("z");    graph.append("text")            .attr("x", (width / 2))            .attr("y", -10)            .attr("text-anchor", "middle")            .style("font-size", "16px")            .text("sigmoid function");  </script></p><p>  Սա քայլ ֆունկցիայի (step function) «հարթեցված» տարբերակն է:
</p><p>  <div id="step_graph"></div>  <script>  function s(x) {return x < 0 ? 0 : 1;}  var m = [40, 120, 50, 120];  var height = 290 - m[0] - m[2];  var width = 600 - m[1] - m[3];  var xmin = -5;  var xmax = 5;  var sample = 400;  var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);  var data = d3.range(sample).map(function(d){ return {          x: x1(d),          y: s(x1(d))};      });  var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);  var y = d3.scale.linear()                  .domain([0,1])                  .range([height, 0]);  var line = d3.svg.line()      .x(function(d) { return x(d.x); })      .y(function(d) { return y(d.y); })  var graph = d3.select("#step_graph")      .append("svg")      .attr("width", width + m[1] + m[3])      .attr("height", height + m[0] + m[2])      .append("g")      .attr("transform", "translate(" + m[3] + "," + m[0] + ")");  var xAxis = d3.svg.axis()                    .scale(x)                    .tickValues(d3.range(-4, 5, 1))                    .orient("bottom")  graph.append("g")      .attr("class", "x axis")      .attr("transform", "translate(0, " + height + ")")      .call(xAxis);  var yAxis = d3.svg.axis()                    .scale(y)                    .tickValues(d3.range(0, 1.01, 0.2))                    .orient("left")                    .ticks(5)  graph.append("g")      .attr("class", "y axis")      .call(yAxis);  graph.append("path").attr("d", line(data));  graph.append("text")       .attr("class", "x label")       .attr("text-anchor", "end")       .attr("x", width/2)       .attr("y", height+35)       .text("z");  graph.append("text")          .attr("x", (width / 2))          .attr("y", -10)          .attr("text-anchor", "middle")          .style("font-size", "16px")          .text("step function");  </script></p><p>  Եթե $\sigma$-ն լիներ քայլ ֆունկցիան, ապա սիգմոիդ նեյրոնը կլիներ պերսեպտրոնը,  քանի որ ելքում կստացվեին $1$ կամ $0$ արժեքները՝ կախված նրանից, թե $w\cdot x+b$
  դրական է, թե բացասական*:  <span class="marginnote">    *Իրականում, $w \cdot x +b = 0$ պերսեպտրոնի արժեքը $0$ է, երբ քայլ ֆունկցիայի    արժեքը $1$ է: Այսպիսով, ճշգրիտության համար նշեմ, որ քայլ ֆունկցիայի արժեքը այդ
    կետում կարիք կլինի փոխել: Այնուամենայնիվ, կարծում եմ ընդհանուր գաղափարը պարզ է:
  </span>  Օգտագործելով $\sigma$ ֆունկցիան, մենք ստանում ենք պերսեպտրոնի փոքր-ինչ հարթեցված  տարբերակը, ինչն ամենակարևորն է, քանի որ դա նշանակում է, որ կշռի $\Delta w_j$ և շեղման
  $\Delta b$ փոքր փոփոխությունների արդյունքում վերջնական արժեքի փոփոխությունը $\Delta \mbox{ելք}$–ը
  նույնպես փոքր կլինի: Ըստ էության, $\Delta \mbox{ելք}$-ը կարելի է մոտարկել հետևյալ կերպ
  <a class="displaced_anchor" name="eqtn5"></a>  \begin{eqnarray}    \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}    \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b} \Delta b,    \tag{5}  \end{eqnarray}  որտեղ գումարն ըստ բոլոր $w_j$ կշիռների է, իսկ $\partial \,  \mbox{ելք} / \partial w_j$ և $\partial \, \mbox{ելք} /\partial  b$ ելքի  մասնակի ածանցյալներն են ըստ $w_j$ և $b$ փոփոխականների
  համապատասխանաբար: Խնդրում եմ խուճապի չմատնվել, եթե մասնակի ածանցյալները հարմարավետ չեն
  ձեզ համար: Կարող է թվալ, որ վերևի արտահայտությունը բարդ է, սակայն այն ուղղակի նշանակում է,  որ  $\Delta \mbox{ելք}$-ը գծային ֆունկցիա է $\Delta w_j$ և $\Delta b$ կշիռների և շեղման  փոփոխություններից կախված: Գծայնությունը թույլ է տալիս հեշտությամբ ընտրել կշիռների և շեղումների
  փոքր փոփոխություն այնպես, որ հանգեցնի փոքր փոփոխություն ելքում: Այսպիսով սիգմոիդները,
  ունենալով պերսեպտրոններին նման որակական հատկանիշներ, միաժամանակ թույլ են տալիս հեշտությամբ  հասկանալ, թե կշիռների և շեղման փոփոխությունը ինչպիսի ազդեցություն կունենա նեյրոնի ելքի վրա:
</p><p>  Քանի որ ավելի մեծ կարևորություն ենք տալիս $\sigma$ ֆունկցիայի գրաֆիկի տեսքին, քան ինքնին ֆունկցիային, ապա ինչու՞
  օգտագործենք $\sigma$-ի
  <span id="margin_850263336921_reveal" class="equation_link">(3)</span>  <span id="margin_850263336921" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn3" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}        \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber      \end{eqnarray}    </a>  </span>  <script>    $('#margin_850263336921_reveal').click(function() {$('#margin_850263336921').toggle('slow', function() {});});  </script>  -ում տրված տեսքը: Ավելի ուշ մենք կտեսնենք այնպիսի նեյրոններ, որոնց արժեքը $f(w \cdot x + b)$ որոշվում է
  այլ $f(\cdot)$ <em>ակտիվացման ֆունկցիայի (activation function)</em> միջոցով: Ակտիվացման ֆունկցիայի փոփոխության
  հետևանքով
  <span id="margin_444952422305_reveal" class="equation_link">(5)</span>  <span id="margin_444952422305" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn5" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta \mbox{ելք} \approx \sum_j \frac{\partial \, \mbox{ելք}}{\partial w_j}      \Delta w_j + \frac{\partial \, \mbox{ելք}}{\partial b}      \Delta b \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_444952422305_reveal').click(function() {$('#margin_444952422305').toggle('slow', function() {});});  </script>  հավասարման մեջ կարող են փոխվել միայն մասնակի ածանցյալների արժեքները: Հեշտ է նկատել նաև,
  որ վերոնշյալ մասնակի ածանցյալները հաշվելիս $\sigma$ ֆունկցիան հաշվման գործընթացը
  կհեշտացնի, քանի որ էքսպոնենցիալ ֆունկցիաները դիֆերենցելիս հրաշալի հատկություններ ունեն։
  Այնուամենայնիվ, $\sigma$-ն բավականին տարածված է նեյրոնային ցանցերում որպես ակտիվացման ֆունկցիա, և մենք  այն բավականին հաճախ կօգտագործենք այս գրքում:
</p><p>  Իսկ ինչպե՞ս պետք է մեկնաբանել սիգմոիդ նեյրոնի ելքը (արժեքը): Հեշտ է նկատել, որ
  համեմատած պերսեպտրոնին, սիգմոիդ նեյրոնի ելքում միայն $0$ կամ $1$ չէ, այլ $0$-ից $1$ միջակայքում
  գտնվող արժեքներ (օրինակ $0.173\ldots$ կամ $0.689\ldots$ և այլն): Այդ հատկությունը
  կարելի է օգտագործել բազմաթիվ ձևերով: Օրինակ, այն կարելի է օգտագործել ելքային արժեքը  որպես նկարի (որպես նեյրոնային ցանցին մուտքային արժեքներ) պիքսելների միջին ինտենսիվություն ներկայացնելու համար:
  Սակայն երբ նպատակը ելքը բինար արժեքով ներկայացնելն է (օրինակ մուտքային նկարը "9" է կամ "9" չէ),
  ապա այդ դեպքում կարելի է օգտագործել այլ մարտավարություն` եթե արժեքը $0.5$-ից փոքր է, ապա "9" է և
  համապատասխանաբար "9" չէ երբ ելքի արժեքը $0.5$-ից փոքր չէ: Նմանատիպ պայմանավորվածությունները  հստակ կնշվեն գրքի հետագա քննարկումներում, որպեսզի շփոթություն չառաջանա:
</p><p>  <h4>    <a name="exercises_191892"></a>    <a href="#exercises_191892">Վարժություններ</a>  </h4>  <ul>    <li>    <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս I</strong>    $\mbox{}$ <br/>    Ենթադրենք պերսեպտրոնների ցանցի բոլոր շեղումները և կշիռները բազմապատկում ենք    $c > 0$ դրական հաստատունով: Ցույց տվեք, որ ցանցի վարքագիծը դրանից չի փոխվում:    </p><p>    <li>      <strong>Պերսեպտրոն սիմուլացնող սիգմոիդ նեյրոններ, մաս II</strong>      $\mbox{}$ <br/>      Դիտարկենք պերսեպտրոնների ցանց: Ենթադրենք ցանցի մուտքն արդեն ընտրված է:      Մուտքային արժեքը էական չէ, էական է այն, որ այն ֆիքսված է:      Ենթադրենք կշիռներն ու շեղումները բավարարում են $w \cdot x + b \neq 0$ պայմանին      $x$ մուտքի և ցանցի կամայական պերսեպտրոնի համար: Այժմ փոխարինենք ցանցի բոլոր պերսեպտրոնները      սիգմոիդ նեյրոններով և բազմապատկենք կշիռներն ու շեղումները $c > 0$ հաստատունով:      Ցույց տվեք, որ երբ $c \rightarrow \infty$, ապա սիգմոիդ նեյրոնների ցանցի վարքագիծը      նույնն է, ինչ պերսեպտրոնների ցանցինը: Ինչպե՞ս վերոնշյալ հատկությունը կարող է տեղի չունենալ      գոնե մեկ պերսպտրոնի համար, որը չի բավարարում $w \cdot x + b = 0$ պայմանին:</ul></p><p>  <h3>    <a name="the_architecture_of_neural_networks"></a>    <a href="#the_architecture_of_neural_networks">      Նեյրոնային ցանցերի կառուցվածքը    </a>  </h3></p><p>  Հաջորդ բաժնում կներկայացնենք նեյրոնային ցանց, որը բավականին հաջողությամբ կարողանում է  դասակարգել ձեռագիր թվանշանները: Որպես նախապատրաստական աշխատանք, նպատակահարմար է  բացատրել որոշ տերմիններ, որը մեզ թույլ կտա անվանումներ տալ ցանցի բաղադրիչներին: Ենթադրենք, որ  ունենք որևէ ցանց.  <center>    <img src="images/tikz10.png"/>  </center>  Հայտնի է արդեն, որ ամենից ձախ գտնվող շերտը կոչվում է մուտքային շերտ, որին պատկանող  նեյրոնները համապատասխանաբար կոչվում են <em>մուտքային նեյրոններ</em>: Աջակողմյան շետը  կոչվում է <em>ելքային</em> (վերը նշված դեպքում միակ ելքային նեյրոն): Միջին շերտերը կոչվում են  <em>թաքնված շերտեր</em>, քանի որ այս շերտի նեյրոնները ոչ մուտքային են, ոչ ելքային: Չնայած նրան,  որ թաքնված տերմինը միստիկ հնըչողություն ունի, սակայն այն ոչ մի խորը մաթեմատիկական կամ փիլիսոփայական  նշանակություն չունի, այն պարզապես նշանակում ո՛չ մուտքային, ո՛չ ելքային: Վերևում նկարված ցանցը  ունի միայն մեկ թաքնված շերտ, սակայն որոշ ցանցեր ունենբազմաթիվ թաքնված շերտեր: Օրինակ, հետևյալ  չորս շերտանոց ցանցն ունի երկու թաքնված շերտ.  <center>    <img src="images/tikz11.png"/>  </center>  Նշենք, որ պատմականորեն, այդպիսի բազմաշերտ ցանցերը ինչ-ինչ պատճառով կոչվում են  <em>բազմաշերտ պերսեպտրոններ</em>` չնայած անյն փաստին, որ իրենք կառուցված են սիգմոիդներից  այլ ոչ պերսեպտրոններից: Մենք չենք օգտագործի այդպիսի տերմինաբանություն, քանի-որ այն  շփոթոյթյան մեջ կարող է գցել ընթերցողին:</p><p>  Մուտքային և ելքային շերտերի կառուցվածքները հիմնականում ակնհայտ են լինում:  Օրինակ, ենթադրենք ցանկանում ենք պարզել արդյոք ձեռագիր թվանշանը  ցույց է տալիս "9" թիվը: Ցանցը կառուցելու բնական մեթոդը կլինի նկարի պիքսելների  խտության արտապատկերումը մուտքային նեյրոններին: Եթե նկարը $64$-ը $64$-ի վրա  անգույն նկար է, այդ դեպքում կունենանճ $4,096 = 64 \times 64$ մուտքային նեյրոններ,  որտեղ խտությունները նորմավորված են $0$-ից $1$ միջակայքում: Ելքային շերտը կպարունակի  միայն մեկ նեյրոն, որի արժեքի $0.5$-ից մեծ լինելը կնշանակի նկարը 9 է, իսկ փոքր լինեու դեպքպւմ` ոչ:</p><p></p><p></p><p>  Մինչդեռ նեյրոնային ցանցի մուտքային և ելքային շերտերի կառուցվածքը հիմնականում ակնհայտ է, սակայն  թաքնված շերտերի կառուցվածքը կարող է էապես բարդ լինել: Բավականին դժվար է ընդհանուր բնութագրել  թաքնված շերտերի կառուցման պրոցեսը մի քանի ընդհանուր պնդումներով: Փոխարենը նեյրոնային ցանցեր  հետազոտողները ստեղծել են բազմաթիվ կառուցվածքներ, մոտեցումներ, որոնք օգնում են ստանալ նպատակային  արդյունքը` օգտագործելով նեյրոնային ցանցեր: Մենք կհանդիպենք այդպիսի կառուցվածքներից մի քանիսին  ավելի ուշ գրքում:</p><p>  Մինչ այժմ մենք քննարկում էինք այնպիսի նեյրոնային ցանցեր, որոնցում մի շերտի ելքն  օգտագործվում է որպես մուտք հաջորդ շերտի համար: Այդպիսի ցանցերը կոչվում են  <em>առաջաբեր(feedforward)</em> նեյրոնային ցանցեր: Սա նշանակում է, որ ցանցում  չկան ցիկլեր. ինֆորմացիան միշտ առաջ է բերվում և ոչ մի դեպքում ետ: Եթե թույլ տայինք ցիկլեր,  ապա կստացվեր, որ $\sigma$-ի մուտքը կախված կլիներ ելքից, այդ պատճառով մենք թույլ չենք տալիս  այդպիսի ցիկլեր:</p><p>  Սակայն գոյություն ունեն այնպիսի նեյրոնային ցանցեր, որոնց մեջ ցիկլերը հնարավոր են:  Այդպիսի մոդելները կոչվում են <a href="http://en.wikipedia.org/wiki/Recurrent_neural_network">ռեկուրենտ նեյրոնային ցանցեր</a>: Գաղափարը կայանում է նրանում, որ այդպիսի մոդելներում նեյրոնը  աշխատի ինչ-որ սահմանափակ ժամանակ մինչև պասիվանալը: Այդ աշխատանքը կարող է խթանել  այլ նեյրոններին, որպեսզի նրանք էլ սկսեն աշխատել ինչ-որ ժամանակ անց ինչ-որ չափավոր ժամանակով:  Այդ իր հերթին հանգեցնում է նոր նեյրոնների աշխատանքին, այսպիսով հանգեցնելպվ նեյրոններ կասկադային  աշխատանքին: Ցիկլերն այս դեպքում ոչնչի վրա չեն ազդում, քանի որ նեյրոնի ելքը ազդեցություն ունի  մուտքի վրա ինչ-որ ժամանակ անց, այլ ոչ անմիջապես:</p><p></p><p>  Ռեկուրենտ նեյրոնային ցանցերում հետազոտությունները ժամանակի ընթացքում ավելանում են,  հետևաբար նաև կիրառությունները: Այս տեսակի ցանցերը ըստ էության, ավելի մոտիկ են ուղեղի  աշխատանքի մոդելին, քան առաջաբեր ցանցերը: Ռեկուրենտ ցանցերն ունակ են լուծելու այնպիսի  խնդիրներ, որոնք առաջաբեր ցանցերի համար մեծ դժվարություն են ներկայացնում: Այնուամենայնիվ,  սահմանափակելով մեր շրջանակը, այս գրքում կկենտրոնանք ավելի լայնորեն կիրառվող առաջաբեր  ցանցերի վրա:</p><p>  <h3>    <a name="a_simple_network_to_classify_handwritten_digits"></a>    <a href="#a_simple_network_to_classify_handwritten_digits">      Պարզ ցանց ձեռագիր թվանշանները ճանաչելու համար    </a>  </h3></p><p>  Վերադառնանք ձեռագիր թվերի ճանաչման խնդրին: Մենք կարող ենք խնդիրը բաժանել  երկու ենթախնդիրների: Առաջինը` բաժանենք բազմաթիվ նկարներ պարունակող նկարը  մի թվանշան պարունակող նկարների հերթականության: Օրինակ, մենք նպատակադրված ենք  բաժանել հետևյալ նկարը.</p><p><center><img src="images/digits.png" width="300px"></center></p><p>  6 առանձին նկարների,</p><p><center><img src="images/digits_separate.png" width="440px"></center></p><p>  Մենք` մարդիկս այս <em>սեգմենտացիայի խնդիրը</em> հեշտությամբ ենք լուծում, սակայն  համակարգչային ծրագրի համար հեշտ խնդիր չէ նկարը ճշգրիտ բաժանելը: Նկարը մասնատելուց հետո  ծրագիրը պետք է տարբերակի յուրաքանչյուր առանձին թվանշան: Օրինակ, մենք կուզենայինք, որ մեր  ծրագիրը վերևի թվերից առաջինը ճանաչեր որպես 5.</p><p><center><img src="images/mnist_first_digit.png" width="64px"></center></p><p>  Կենտրոնանք վերը նշված խնդիրներից երկրորդի վրա, այն է` ինդիվիդուալ թվանշանների տարբերակման  խնդիրը: Ընտրում ենք այս ուղղությունը, քանի որ պարզվում է, որ բաժանման խնդիրն այդքան էլ դժվար չէ լուծելը,  եթե ունես թվանշանները տարբերակելու լավ լուծում: Բաժանման խնդիրը լուծելու բազմաթիվ  մոտեցումներ կան: Մոտեցումներից մեկն է` փորձել տարբեր ձևերով բաժանել և թույլ տալ, որպեսզի թվանշաններ  ճանաչող ծրագիրը գնահատականներ տա բաժանումներին: Բաժանումը գնահատվում է կախված նրանից թե ինդիվիդուալ  թվանշան տարբերակող ծրագիրն ինչքան "վստահ" բաժանվածի բոլոր մասերում տարբերակված թվանշանների  հարցում, ընդ որում` որքան շատ են այն բաժինները, որում տարբերակումը վստահ չէ, այնքան ավելի ցածր է գնահատականը:  Իդեան կայանում է նրանում, որ եթե տարբերակող ծրագիրը դժվարանում է տարբերակել գոնե մի բաժնում, ապա դրա  պատճառն  ամենայն հավանականությամբ սխալ բաժանման մեջ է կայանում: Ընդ որում սա օրինակներից մեկն է, թե ինչպես կարելի  է լուծել բաժանման խնդիրը: Այդ իսկ պատճառով, բաժանման խնդրի փոխարեն մենք կկենտրոնանանք թվանշաններ  ճանաչելու համար նախատեսված նեյրոնային ցանց նախագծելու վրա:</p><p>  Ինդիվիդուալ թվանշան ճանաչելու նպատակով մենք կկառուցենք եռաշերտ նեյրոնային ցանց.</p><p>  <center><img src="images/tikz12.png"/></center></p><p>  Ցանցի մուտքային շերտը պարունակում է կոդավորված մուտքային պիքսելները: Ինչպես քննարկվում է  հաջորդ բաժնում, ուսուցման տվյալները իրենցից ներկայացնում են $28$ պիքսել երկարությամբ և լայնությամբ  ձեռագիր թվանշանների նկարներ, հետևաբար մուտքային շերտը պարունակում է $784 = 28 \times 28$  նեյրոններ: Պարզության համար, վեևրևի գծանկարում $784$ նեյրոններից շատերը բաց են թողնված: Մուտքային  պիքսելները մոխրագույն են, այնպես, որ $0.0$-ն ներկայացնում է սպիտակը իսկ $1.0$-ը` սևը, իսկ այդ միջակայքում  գտնվող արժեքները ներկայացնում են մոխրագույնի աստիճանաբար մգացող երանգները:</p><p>  Ցանցի երկրորդ շերտը թաքնված է: Երկրորդ շերտի նեյրոնների քանակը նշանակենք $n$, որի  արժեքի շուրջ կկատարենք բազմաթիվ փորձեր: Օրինակը ներկայացնում է համեմատաբար  փոքր թաքնված շերտ, որը պարունակում է $n = 15$ նեյրոններ:</p><p>  Ցանցի ելքային շերտը պարունակում է 10 նեյրոններ: Եթե առաջին նեյրոնի արժեքը, օրինակ  $\approx 1$ (մոտ է 1-ին), ապա դա նշանակում է, որ ցանցը կարծում է, որ թվանշանը $0$ է:  Երբ երկրորդ նեյրոնն ունի այդ հատկությունը, ապա դա կնշանակի, որ ցանցը կարծում է՝, որ  թվանշանը $1$ է և այդպես շարունակ: Այսպիսով, մենք ելքային նեյրոնները համարակալում ենք  $0$-ից $9$ և պարզում, թե որ նեյրոնն ունի մեծագույն ակտիվացիայի արժեքը: Եթե այդ նեյրոնը,  ենթադրենք, $6$-ն է, ապա ցանցը ցույց է տալիս, որ թվանշանը $6$-ն է և այդպես շարունակ:</p><p>  Հարց է առաջանում, թե ինչու ենք օգտագործում $10$ ելքային նայրոններ: Վերջիվերջո  ցանցի նպատակն է ցույց տալ, թե ($0, 1, 2, \ldots, 9$) թվանշաններից որին է  համապատասխանում մուտքային նկարը: թվում է բնական է օգտագործել ելքային $4$ նեյրոն,  որոնցից յուրաքանչյուրը կունենա բինար արժեք` կախված նրանից, թե $0$-ից $1$ միջակայքի  որ մասում է արժեքը: Չորս նեյրոնները բավարար են պատասխանը կոդավորելու հանար,  քանի որ $2^4 = 16$, որը մեծ է 10 հնարավոր արժեքների քանակից: Ինչու՞ մեր ցանցը $10$  նեյրոն օգտագործի փոխարենը: Միթե դա ոչ էֆֆեկտիվ չէ: Պատասխանը էմպիրիկ է. իրականում կարելի  է փորձել երկու ձևերով էլ: Պարզվում է, որ հենց այս խնդիրը $10$ ելքային նեյրոններով ավելի լավ  է սովորում թվանշանները ճանաչել, քան $4$ ելքային նեյրոններով: Այնումամենայնիվ, մեզ հետաքրքիր է,  թե <em>ինչու</em> է $10$ ելքերով ցանցն աշխատում ավելի լավ: Հնարավո՞ր է արդյոք նախորոք  որոշել, թե $10$ կամ $4¢ է պետք օգտագործել:</p><p>  Որպեսզի պարզենք, թե ինչու ենք այդպես վարվում, փորձենք հասկանալ, թե ինչպես է աշխատում  նեյրոնային ցանցը: Ենթադրենք օգտագործում ենք $10$ ելքային նեյրոններ: Դիտարկենք  առաջին ելքային նեյրոնը, որը պատասխանատու է որոշելու համար արդյոք մոտքային նկարը $0$ է:  Դա տեղի է ունենում թաքնված շերտերից ստացված "վկայությունները" "համեմատելով": Ի՞նչպես են աշխատում  թաքնված շերտերը: Ենթադրենք թաքնված շերտի առաջին նեյրոնը որոշում է արդյոք ներքևում նշված նկարն  առկա է, թե ոչ:</p><p><center><img src="images/mnist_top_left_feature.png" width="130px"></center></p><p>  Դա կարելի է անել մուտքային պիքսելներին, որոնք հատվում են նկարին համապատասխանող պիքսելների  ծանր կշիռներ տալով և համեմատաբար թեթև կշիռներ տալով մնացած մոտքային պիքսելներին: Նույն ձևով,  ենթադրենք, որ երկրորդ, երրորդ և չորրորդ նեյրոնները թաքնված շերտում որոշում են արդյոք հետևյալ նկարները  ազատ են:</p><p><center><img src="images/mnist_other_features.png" width="424px"></center></p><p>  Ակնհայտ է, որ այդ չորս նկարները միասին կազմում են $0$ նկարը:  <a href="#complete_zero">earlier</a>:</p>  <p><center><img src="images/mnist_complete_zero.png" width="130px"></center></p><p>  Այսպիսով, եթե թաքնված նեյրոնների բոլոր 4 նեյրոնները աշխատում են, ապա  եզրակացնում ենք, որ թվանշանը մոտ է $0$-ին: Իհարկե դա <em>միակ</em>  միակ վկայությունը չէ, որից կարող ենք եզրալացնել, որ թվանշանը $0$-ն է: Մենք  կարող ենք օրինականորեն ստանալ $0$ բազմաթիվ այլ ձևերով (օրինակ վերևի նկարների  նկատմամբ փոփոխություններ կատարելով):</p><p></p><p></p><p></p><p>  Ենթադրելով, որ նեյրոնային ցանցն աշխատում է այսպես, կարող ենք տալ խելամիտ  բացատրություն, թե ինչու է նպատակահարմար օգտագործել $10$ ելք $4$-ի փոխարեն:  Եթե ունենայինք $4$ ելքեր, ապա առաջին ելքային նեյրոնը փորձելու էր որոշելու թվանշանի  առաջին բիթը: Եվ հեշտ ձև չկա առաջին բիթը կապելու վերևում տրված պարզ նկարի հետ:</p><p>  Այսպիսով, այս ամենը ոչ ճշգրիտ է: Ոչնչից չի հետևում, որ պարզ եռաշերտ նեյրոնային  ցանցը պարտավոր է աշխատել նկարագրված ձևով` թաքնված շերտերը գուշակելով պարզ  կոմպոնենտների տեսքերը: Հնարավոր է, որ խելոք սովորող ալգորիթմը գտնի կշիռների  այնպիսի դասավորվածություն, որը թույլ տա օգտագործել $4$ ելքային նեյրոններ:</p><p>  <h4>    <a name="exercise_513527"></a>    <a href="#exercise_513527">Վարժություն</a>  </h4>  <ul>    <li>      Գոյություւն ունի մոտեցում, որը հնարավորություն է տալիս գտնել թվի երկակի(բիթային) ներկայացումը      վերևում նշված ցանցին ևս մեկ շերտ ավելացնելով: Նոր շերտը նախորդ շերտի շերտի արժեքը փոխակերպում է      բինար ներկայացման ինչպես ներկայացված է ներքևում: Գտնել նոր ելքային շերտի կշիռներն ու շեղումները:      Կարող եք ենթադրել, որ նեյրոնների առաջին $3$ շերտերն այնպիսին են, որ երրորդ շերտից ճիշտ արժէքը      ունի ամենաքիչը $0.99$ հավանականություն և ոչ ճշգրիտ արժեքներն ունեն $0.01$-ից փոքր արժեք:  </ul></p><p>  <center><img src="images/tikz13.png"/></center></p><p></p><p></p><p></p><p>  <h3>    <a name="learning_with_gradient_descent"></a>    <a href="#learning_with_gradient_descent">Գրադիենտային իջեցմամբ ուսուցում</a>  </h3></p><p></p><p>  Այժմ, երբ մենք ունենք նեյրոնային ցանցի կառուցվածք, ինչպես այն կարող է սովորել ճանաչել  թվանշաններ: Առաջինն ինչ մեզ պետք է, դա ուսուցման համար նախատեսված տվյալների բազմությունն է  (ուսուցման տվյալների բազմություն): Մենք կօգտագործենք  <a href="http://yann.lecun.com/exdb/mnist/">MNIST տվյալների բազմությունը</a>,  որը պարունակում է տաս հազարավոր ձեռագիր թվանշանների նկարներ իրենց ճշգրիտ թվային արժեքներով:  MNIST անունը գալիս է նրանից, որ այն Միացյալ Նահանգների  <a href="http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>-ի  (National Institute of Standards and Technology) կողմից հավաքագրված երկու տվյալների  բազմությունների փոփոխության ենթարկված տարբերակն է: Ահա մի քանի նկարներ MNIST-ից:</p><p>  <center><img src="images/digits_separate.png" width="420px"></center></p><p>  Ինչպես տեսնում եք այս թվանշաններն ըստ էության նույնն են ինչ ցույց էր տրված  <a href="#complete_zero">գլխի սկզբում</a> որպես ճանաչման խնդիր: Իհարկե  ցանցը սովորեցնելուց կփորձարկենք նկարների վրա, որոնք ուսուցման տվյալների բազմությունում  չկան:</p><p>  MNIST-ի տվյալները բաղկացած են երկու մասից: Առաջին մասը պարունակում է 60,000  նկարներ, որոնք կօգտագործվեն որպես ուսուցման տվյալներ: Այդ նկարները 250 մարդկանց  սկանավորված ձեռագիր թվանշաններ են այնպես, որ մարդկանցից կեսը Միացյալ Նահանգների  մարդահամարի բյուրոյի աշխատակիցներն են, մյուս կեսը ավագ դպրոցի աշակերտներ: Նկարները  մոխրագույն են և 28-ը 28-ի վրա: MNIST տվյալների բազմության երկրորդ մասը 10,000 նկարներից  է բաղկացած, որը կօգտագործվի որպես թեստային տվյալներ: Կրկին նկարները մոխրագույն են և 28-ը  28-ի վրա: Մենք կօգտագործենք թեստային տվյալները որոշելու համար, թե ինչքան լավ է մեր նեյրոնային  ցանցը սովորել թվանշանների ճանաչումը: Որպեսզի թեստավորումը լավը լինի, թեստային տվյալների բազմությունը  վերցված է 250 <em>ուրիշ</em> մարդկանց բազմությունից: Սա մեզ վստահություն է տալիս, որ համակարգը  կարող է ճանաչել այն մարդկանց ձեռագրերը, ոնը նախկինում չի հանդիպել ուսուցման ժամանակ:</p><p>  Ուսուցման մուտքը նշանակենք $x$-ով: Ընդ որում մուտքային $x$ վեկտորը $28 \times 28 =  784$ չափանի վեկտոր է,որի ամեն անդամը ներկայացնում է մեկ պիքսելի մոխրագույն արժեքը:  Նշանակենք համապատասխան ելքային արժեքը $y = y(x)$, որտեղ $y$-ը $10$ չափանի վեկտոր է:  Օրինակ, եթե որոշակի ուսուցման վեկտորը ներկայացնում է 6 թվանշանը, ապա  $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ ցանցի ցանկալի ելքային վեկտորն է, որտեղ $T$-ն  տրանսպոնացման գործողությունն է (որը տողային վեկտորը վերածում է սյունակային վեկտորի և հակառակը):</p><p>  Մեր նպատակն է գտնել մի այլպիսի ալգորիթմ, որը հնարավորություն է տալիս  հաշվել այնպիսի կշիռներ և շեղումներ, որ ցանցի ելքային արժեքը մոտարկի $y(x)$-ը  բոլոր $x$ մուտքային արժեքների դեպքում: Որպեսզի հաշվարկենք, թե ինչ հաջողություններ  կան նպատակին հասնելու առումով, սահմանենք <em>արժեքի ֆունկցիա(cost function)</em>*  <span class="marginnote">    *Երբեմն հղվում են որպես <em>կորստի (loss)</em> կամ <em>նպատակային (objective)</em>    ֆունկցիա: Մենք օգտագործում ենք արժեքի ֆունկցիա տերմինը գրքում, սակայն խորհուրդ է տրվում    հաշվի առնել, որ նշված ալտերնատիվ տերմինները նույնպես լայն օգտագործում ունեն, հատկապես    գիտական հոդվածներում:  </span>:  <a class="displaced_anchor" name="eqtn6"></a>  \begin{eqnarray}  C(w,b) \equiv    \frac{1}{2n} \sum_x \| y(x) - a\|^2.  \tag{6}\end{eqnarray}  Որտեղ $w$-ով նշանակված է ցանցում բոլոր կշիռների բազմությունը, $b$-ով նշանակված  են բոլոր շեղումները, $n$-ը ուսուցման մուտքերի քանակն է, $a$-ն ցանցի ելքային վեկտորն է  $x$ մուտքի դեպքում և գումարը բոլոր մուտքային $x$-երով է: Իհարկե, $a$ ելքային արժեքը  կախված է $x$-ի, $w$-ի and $b$-ի արժեքներից, սակայն պարզությունը պահելու համար, այդ  կախվածությունը նշված չէ բանաձևում: $\| v \|$ նշանակումը ցույց է տալիս $v$-ի երկարության  ֆունկցիան: Կոչենք $C$-ն <em>քառակուսային</em> արժեքի ֆունկցիա. այն հայտնի է նաև որպես  <em>Միջին Քառակուսային Սխալ</em>: Դիտարկելով քառակուսային արժեքի ֆունկցիան, եզրակացնում  ենք, որ $C(w,b)$-ն ոչ բացասական է, քանի որ յուրաքանչյուր անդամը ոչ բացասական է: Ավելին,  $C(w,b)$ արժեքը փոքրանում է (օրինակ $C(w,b) \approx 0$), երբ $y(x)$-ի արժեքը  մոտենում է ելքային $a$ արժեքին բոլոր $x$ ուսուցման մուտքերի համար: Այսպիսով, կարելի է ասել,  որ ալգորիթմը լավ է աշխատում, երբ այն կարողանում է գտնել կշիռների և շեղումների այնպիսի արժեքներ,  որ $C(w,b) \approx 0$: Նմանապես, այն լավ չի աշխատում, երբ $C(w,b)$ մեծ արժեք ունի,  ինչը նշանակում է $y(x)$ մոտիկ չէ $a$  ելքերին, մեծ քանակությամբ արժեքների դեպքում: Այսպիսով,  մեր ուսուցման ալգորիթմի նպատակն է լինելւ մինիմիզացնել $C(w,b)$ արժեքը որպես ֆունկցիա կշիռներից  և շեղումներից: Այսպիսով, մենք ուզում ենք գտնել այնպիսի կշիռների և շեղումների բազմություն, որը  արժեքը դարձնում է ինչքան հնարավոր է փոքր: Մենք դա կանենք օտգագործելով  <em>գրադիենտային իջեցման (gradient descent)</em> ալգորիթմը:</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>  Ինչու՞ դիտարկել քառակուսային արժեքը, չէ՞ որ մեր վերջնական նպատակն է  ունենալ մեծ քանակությամբ նկարներ ճիշտ տարբերակված ցանցի կողմից:  Ինչու՞ չմաքսիմիզացնել ճիշտ գուշակված նկարների քանակը, փոխարենը դիտարկելու  այնպիսի մի միջանկյալ մեծություն ինչպիսին է քառակուսային արժեքը: Խնդիրը կայանում  է նրանում, որ ճիշտ տարբերակված նկարների քանակի ֆունկցիան կախված ցանցի  կշիռներից և շեղումից այնքան էլ հարմար չէ օպտիմիզացիայի խնդիր լուծելու համար:  Այն է` կշիռների և շեղման փոքր փոփոխությունը չի հանգեցնի ոչ մի փոփոխության  ճիշտ տարբերակված նկարների քանակի մեջ: Այդ իսկ պատճառով դժվար է հասկանալ,  թե ինչպես փոփոխել կշիռներն ու շեղումները, որպեսզի բարելավվի ալգորիթմի կատարողականությունը:  Պարզվում է, որ եթե փոխարենը վերցնենք այնպիսի արժեքի ֆունկցիա, ինչպիսին է քառակուսային  արժեքի ֆունկցիան, կշիռների և սեղումների փոքր փոփոխությունները կհանգեցնեն արժեքի  բարելավման: Այդ իսկ պատճառով, մենք սկզբում կկենտրոնանք արժեքի ֆունկցիան  մինիմզացնելու վրա, այնուհետև կդիտարկենք տարբերակման ճշտությունը:</p><p></p><p>  Անգամ եթե հայտնի է, որ մենք ուզում ենք այնպիսի ֆունկցիա, որի հետ հեշտ լինի  աշխատել օպտիմիզացիայի առումով, մեկ է հարց է առաջանում, թե ինչու ենք ընտրում  հենց քառակուսային ֆունկցիան օգտագործված հավասարում  <span id="margin_432054929623_reveal" class="equation_link">(6)</span>  <span id="margin_432054929623" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a>  </span>  <script>    $('#margin_432054929623_reveal').click(function() {$('#margin_432054929623').toggle('slow', function() {});});  </script>-ում.  Մի գուցե, եթե ընտրեինք այլ ֆունկցիա, կստանայինք մինիմիզացնող կշիռների և շեղումների այլ  բազմություն: Սա արդարացված անհանգստություն է, և այդ պատճառով ավելի ուշ ետ  կվերադառնանք արժեքի ֆունկցիային և կկատարենք որոշ փոփոխություններ: Այնուամենայնիվ,  հավասարում  <span id="margin_488284336334_reveal" class="equation_link">(6)</span>  <span id="margin_488284336334" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a>  </span>  <script>    $('#margin_488284336334_reveal').click(function() {$('#margin_488284336334').toggle('slow', function() {});});  </script>-ի  արժեքի ֆունկցիան հարմար է և բավարար նեյրոնային ցանցերի հիմնական կոնցեպտները  սովորելու համար, հետևաբար, մենք կօգտագործենք դա:</p><p>  Ընդհանրացնելով, մեր նեյրոնային ցանցի ուսուցուման նպատակը կշիռների և շեղումների  որոշումն է, որը մինիմիզացնում է $C(w, b)$ քառակուսային ֆունկցիայի արժեքը:  Սա բավականին հստակ դրված խնդիր է, սակայն այն պարունակում է բազմաթիվ  շեղող մասեր, օրինակ կշիռները, շեղումները, նեյրոնային ցանցի կառուցվածքը և այլն:  Պարզվում է, որ մենք կարող ենք բավականին առաջընթաց ունենալ եթե արհամարհենք  "արժեքի ֆունկցիայի ծագման պատմությունը" և կենտրոնանանք միայն մինիմիզացիայի  վրա: Ենթադրենք, որ ունենք մեկից ավել փոփոխականներից ֆունկցիա և մեր նպատակն  է մինիմիզացնել այդ ֆունկցիան: Մենք կկառուցենք <em>գրադիենտային իջեցման(gradient  descent)</em> մոտեցումը, որը կօգտագործենք մինիմիզացիայի խնդիրը լուծելու համար:  Այնուհերև կվերադառնանք նեյրոնային ցանցերի այն արժեքի ֆունկցիային, որը մենք ուզում  ենք մինիմիզացնել:</p><p>  Այսպիսով, դիտարկենք $C(v)$ ֆունկցիան: Մեր նպատակն է այդ ֆունկցիայի մինիմիզացիան:  Սա կարող է լինել կամայական $v = v_1, v_2, \ldots$ իրական փոփոխականների  ֆունկցիա: Նկատենք, որ $w$ և $b$-ն փոխարինվել էին $v$-ով, որպեսզի ցույց տրվի,  որ $C$-ն կարող է լինել կամայական ֆունկցիա. մենք նեյրոնային ցանցերի կոնտեքստով  այլևս չենք մտածում: $C(v)$-ն մինիմզացնելու համար, ենթադրենք այն երկու  փոփոխականի ֆունկցիա է` $C(v_1, v_2)$:</p><p>  <center><img src="images/valley.png" width="542px"></center></p><p>  Մեր նպատակն է գտնել $C$-ի մինիմումի կետ(եր)ը: Իհարկե, եթե դիտարկենք  վերևում պատկերված ֆունկցիայի գրաֆիկը, ապա կարող ենք տեսնել մինիմումի  կետը: Սակայն դա բավականին պարզ ֆունկցիա է, համեմատած իրականության  մեջ հանդիպող $C$-ի ավելի բարդ կառուցվածքներին (մեկից ավել փոփոխականի  ֆունկցիաներ, որոնց գրաֆիկից ակնհայտ չէ մինիմումի կետերը):</p><p>  Ուրիշ հնարավոր լուծում է օգտագործել մաթեմատիկական անալիզի գործիքները  և գտնել մինիմումը անալիտիկորեն: Մենք կարող ենք հաշվել ածանցյալները և  փորձել գտնել $C$-ի էքստրեմումի կետերը: Սա հնարավոր է, որ աշխատի, եթե  $C$-ն մեկ կամ երկու փոփոխականների ֆունկցիա է, սակայն խնդիրը էապես  կբարդանա, եթե մենք ունենանք շատ ավելի մեծ քանակությամբ փոփոխականներ:  Նեյրոնային ցանցերի համար հատկապես փոփոխականների քանակը շատ ավելի շատ է:  Մեծ ցանցերում արժեքի ֆունկցիաները կարող են կաված լինել միլլիոնավոր կշիռներից  և շեղումներից (ընդ որում, լիելով բավականին բարդ կառուցվածքով ֆունկցիա):  Այսպիսով, օգտագործելով մաթեմատիկական անալիզը, պրակտիկորեն հնարավոր չէ  գտնել մինիմումի կետերը անալիտիկորեն:</p><p><a name="gradient_descent"></a></p><p>  Բարեբախտաբար, հայտնի է ալգորիթմ, որը օգտագործելով կարող ենք լուծել խնդիրը:  Դիտարկենք հետևայլ անալոգիան: Մտածենք մեր ֆոունկցիայի մասին որպես հովիտ:  Պատկերացնենք, որ գնդակը գլորվում է հովիտով դեպի ներքև: Ելնելով ամենօրյա մեր  փոձից, կարող ենք ասել, որ գնդակը վերջիվերջո կհասնի հովիտի ստորոտին: Փոսձենք  օգտագործել այս գաղափարը որպես մինիմումի կետը գտնելու մեթոդ: Մենք կընտրենք  պատահական կետ որպես գնդակի սկզբնակետ և կսիմուլացնենք գնդակի ներքև գլորվելը  ամեն քայլում որոշելով, թե որն է լինելու գնդակի գլորման ուղղությունը (կամ հաջորդ  կետը, որով անցնելու է գնդակը): Մենք դա կարող ենք իրականացնել հաշվելով $C$-ի  ածանցյալները (երբեմն նաև երկրորդ կարգի): Այդ ածանցյալները մեզ ցուցյց կտան, թե  ինչպիսի "տեսք" ունի հովիտը և, հետևաբար, թե ինչպես մեր գնդակը պետք է գլորվի:</p><p>  Տպավորություն կարող է ստեղծվել, որ մենք սկսելու ենք օգտագործել Նյուտոնյան  շարժման հավասարումները գնդակի համար` հաշվի առնելով գրավիտացիան, արագացումը  և այլն: Իրականում մենք գլորվող գնդակի անալոգիային այդպես լրջորեն չենք վերաբերվելու.  մենք դուրս ենք բերում $C$-ի մինիմիզացնելու ալգորիթմ, այլ ոչ ֆիզիկայի օրենքների  ճշգրիտ սիմուլյացիա: Գնդակի օրինակն ուղղակի նախատեսված է պատկերացում կազմելու  համար, թե ինչ ալգորիթմ ենք պատրաստվում կառուցել: Այսպիսով, եթե մենք ունենայինք  սուպեր կարողություններ և կարողանայինք պարտադրել սեփական ֆիզիկայի կանոնները` գնդակին  թելադրելով, թե ինչպես այն պետք է շարժվի, ապա ի՞նչ օրենքներով կորոշեինք գնդակի  շարժումն այնպես որ այն միշտ գլորվեր դեպի ստորոտը:</p><p>  Որպեսզի ճշգրտենք այս հարցը, ապա դիտարկենք, թե ինչ կպատահի, եթե  գնդակը շարժենք $\Delta v_1$-ով $v_1$ ուղղությամբ և $\Delta v_2$-ով  $v_2$-ի ուղղությամբ: Այսպիսով, $C$-ի փոփոխությունը կարելի է հաշվել հետևյալ  բանաձևով.  <a class="displaced_anchor" name="eqtn7"></a>  \begin{eqnarray}    \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +    \frac{\partial C}{\partial v_2} \Delta v_2.  \tag{7}\end{eqnarray}  Եթե $\Delta C$-ն բացասական է, դա կնշանակի, որ $C$-ն նվազում է, այսինքն,  ըստ մեր անալոգիայի, գնդակը գլորվում է դեպի ստորոտ: Հետևաբար, պետք է ընտրենք  $\Delta v_1$-ի և $\Delta v_2$-ի այնպիսի արժեքներ, որպեսզի $C$-ն նվազի ամեն  քայլից հետո: Փորձենք գտնել այդպիսի փոփոխություններ: Նշանակենք  $\Delta v \equiv (\Delta v_1, \Delta v_2)^T$, որտեղ $T$-ն տրանսպոնացման  գործողությունն է: Նշանակենք որպես $C$-ի <em>գրադիենտ</em> մասնակի ածանցյալների  վեկտորը` $\left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial  v_2}\right)^T$. Նշանակենք գրադիենտային վեկտորը հունական նաբլա տառով` $\nabla C$.  <a class="displaced_anchor" name="eqtn8"></a>  \begin{eqnarray}  \nabla C \equiv \left( \frac{\partial C}{\partial v_1},  \frac{\partial C}{\partial v_2} \right)^T.  \tag{8}\end{eqnarray}  Հարկ է նշել, որ $\nabla C$ նշանակումը հնարավոր է ինտերպրետացնել ոչ միանշանակ:  Այն կարելի է դիտարկել որպես մաթեմատիկական օբյեկտ կախված երկու մասից, որոնցից  $\nabla$-ն ուղղակի նշանակում է, որ գրվածը գրադիենտ վեկտոր է: Սակայն կարելի է  $\nabla$-ն դիտարկել որպես անկախ մաթեմատիկական ոբյեկտ, որտեղ այն հանդես է գալիս,  օիրնակ որպես դիֆերենցման օպերատոր: Պայմանավորվենք դիտարկել $\nabla C$-ն առաջին  նկարագրված (ավելի պարզեցված) ձևով:</p><p>  Արտագրենք  <span id="margin_659965637148_reveal" class="equation_link">(7)</span>  <span id="margin_659965637148" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn7" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">    \begin{eqnarray}      \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +    \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_659965637148_reveal').click(function() {$('#margin_659965637148').toggle('slow', function() {});});  </script>  արտահայտությունը որպես  <a class="displaced_anchor" name="eqtn9"></a>  \begin{eqnarray}    \Delta C \approx \nabla C \cdot \Delta v.  \tag{9}\end{eqnarray}  Այս հավասարումն օգնում է բացատրել, թե ինչու է $\nabla C$-ն կոչվում  գրադիենտ: Այն ցույց է տալիս, թե ինչպես է $C$-ի փոփոխությունը կախված  $v$-ի փոփոխությունից: Հետևաբար, այն հնարավորություն է տալիս $\Delta v$-ն  այնպես ընտրել, որ $\Delta C$-ն ստանա բացասական արժեք: Ենթադրենք, որ  ընտրում ենք  <a class="displaced_anchor" name="eqtn10"></a>  \begin{eqnarray}  \Delta v = -\eta \nabla C,  \tag{10}\end{eqnarray}  որտեղ $\eta$-ն բավականաչափ փոքր դրական թիվ է (հայտնի որպես  <em>ուսուցման գործակից (learning rate)</em>).  Հավասարում  <span id="margin_859162866010_reveal" class="equation_link">(9)</span>-ը  <span id="margin_859162866010" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_859162866010_reveal').click(function() {$('#margin_859162866010').toggle('slow', function() {});});  </script>  ցույց է տալիս, որ  $\Delta C \approx -\eta \nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$.  Քանի որ $\| \nabla C \|^2 \geq 0$, ապա $\Delta C \leq 0$, հետևաբար $C$-ն միշտ կնվազի,  եթե $v$-ն ընտրենք հաշվի առնելով հավասարում  <span id="margin_116668158518_reveal" class="equation_link">(10)</span>-ը  <span id="margin_116668158518" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_116668158518_reveal').click(function() {$('#margin_116668158518').toggle('slow', function() {});});  </script>.  (Իհարկե, այնպես, որ չխախտվի մոտավոր հավասարում  <span id="margin_780815505894_reveal" class="equation_link">(9)</span>-ը  <span id="margin_780815505894" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_780815505894_reveal').click(function() {$('#margin_780815505894').toggle('slow', function() {});});  </script>).  Սա ըստ էության այն է, ինչ մենք փնտրում էինք, հետևաբար, մենք կվերցնենք հավասարում  <span id="margin_11850183887_reveal" class="equation_link">(10)</span>-ը  <span id="margin_11850183887" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_11850183887_reveal').click(function() {$('#margin_11850183887').toggle('slow', function() {});});  </script>  որպես "շարժման հավասարում" գնդակի համար: Դա էլ ըստ էության հիմքն է  գրադիենտային իջեցման ալգորիթմ կառուցելու համար: Այսպիսով, օգտագործելով հավասարում  <span id="margin_838405111504_reveal" class="equation_link">(10)</span>-ը  <span id="margin_838405111504" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta v = -\eta \nabla C \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_838405111504_reveal').click(function() {$('#margin_838405111504').toggle('slow', function() {});});  </script>  և հաշվենք $\Delta v$-ի արժեքը, այնուհետև շարժենք գնդակը  $v$ կետից $\Delta v$-ով.  <a class="displaced_anchor" name="eqtn11"></a>  \begin{eqnarray}  v \rightarrow v' = v -\eta \nabla C.  \tag{11}\end{eqnarray}  Այնուհետև կօգտագործենք այս օրենքը ևս մեկ անգամ, շարժելով գնդակը ևս մեկ  քայլով: Շարունակելով այսպես, $C$-ն կնվազի այնքան մինչև ամենայն հավանականությամբ  հասնի գլոբալ մինիմումին (կախված ֆունկցիայի հատկություններից իհարկե):</p><p>  Ընդհանրացնելով, գրադիենտային իջեցման աշխատանքը կայանում է հետևյալում.  հաշվել $\nabla C$ գրադիենտային վեկտորը, այնուհետև շարժվել <em>հակառակ</em>  ուղղությամբ (գլորվելով դեպի հովիտի ստորոտը): Մենք կարող ենք դա պատկերել  հետևյալ կերպ.</p><p>  <center><img src="images/valley_with_ball.png" width="542px"></center></p><p>  Որպեսզի գրադիենտային ուսուցումը ճիշտ աշխատի, պետք է $\eta$-ի արժեքը  վերցնել բավարար չափով փոքր, որ  <span id="margin_261741104421_reveal" class="equation_link">(9)</span>  <span id="margin_261741104421" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray}      \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_261741104421_reveal').click(function() {$('#margin_261741104421').toggle('slow', function() {});});  </script>  հավասարումը դառնա լավ մոտարկում: Հակառակ դեպքում կարող ենք ստանալ  $\Delta C > 0$, ինչը հակասում է մեր նպատակներին: Միևնույն ժամանակ,  եթե $\eta$-ի արժեքը լինի շատ փոքր, ապա $\Delta v$-ի փոփոխությունները  նույնպես կլինի փոքր, հետևաբար գրադիենտային իջեցումը կաշխատի դանդաղ:  Ալգորիթմի պտակտիկ իրականացումներում, $\eta$-ի արժեքը փոխվում է այնպես, որ  <span id="margin_89917482490_reveal" class="equation_link">(9)</span><span id="margin_89917482490" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}    \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_89917482490_reveal').click(function() {$('#margin_89917482490').toggle('slow', function() {});});</script>  հավասարումը լինում է լավ մոտարկում և ալգորիթմը շատ դանդաղ չի լինում:  Հետագայում ավելի մանրամասն կտեսնենք, թե ինչպես է դա տեղի ունենում:</p><p>  Մենք գրադիենտային իջեցմանը ծանոթացանք, ենթադրելով, որ $C$-ն երկու  փոփոխականի ֆունկցիա է: Ըստ էության, ալգորիթմը աշխատում է ճիշտ նույն  ձևով, անգամ եթե $C$-ն երկուսից ավելի փոփոխականի ֆունկցիա է: Ենթադրենք  $C$-ն $v_1,\ldots,v_m$-ից կախված $m$ փոփոխականի ֆունկցիա է: Ապա  $C$-ի $\Delta C$ փոփոխությունը, որն արդյունք է $\Delta v = (\Delta v_1,  \ldots, \Delta v_m)^T$ փոփոխության, կարելի է հաշվել արտահայտել հետևյալ  հավասարումով.  <a class="displaced_anchor" name="eqtn12"></a>\begin{eqnarray}    \Delta C \approx \nabla C \cdot \Delta v,  \tag{12}\end{eqnarray}  որտեղ գրադիենտ $\nabla C$-ն հետևյալ վեկտորն է.  <a class="displaced_anchor" name="eqtn13"></a>\begin{eqnarray}    \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots,    \frac{\partial C}{\partial v_m}\right)^T.  \tag{13}\end{eqnarray}  Ինչպես երկու փոփոխականի դեպքում, կարող ենք որոշել  <a class="displaced_anchor" name="eqtn14"></a>\begin{eqnarray}    \Delta v = -\eta \nabla C,  \tag{14}\end{eqnarray}  և  <span id="margin_737008049048_reveal" class="equation_link">(12)</span><span id="margin_737008049048" class="marginequation" style="display: none;"><a href="chap1.html#eqtn12" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}    \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_737008049048_reveal').click(function() {$('#margin_737008049048').toggle('slow', function() {});});</script>  $\Delta C$-ի արտահայտությունը կլինի բացասական: Դա հնարավորություն է  տալիս մեզ գրադիենտը ձգտեցնել մինիմումի պարբերաբար կիրառելով  <a class="displaced_anchor" name="eqtn15"></a>\begin{eqnarray}    v \rightarrow v' = v-\eta \nabla C.  \tag{15}\end{eqnarray}  օրենքը, անգամ եթե $C$-ն երկուսից ավել փոփոխականներից հավասարում է:  Հենց այս թարմացման օրենքն էլ <em>սահմանում</em> է գրադիենտային իջեցման  ալգորիթմը: Այն հնարավորություն է տալիս շարունակաբար փոխելով $v$-ի դիրքը  գտնել $C$-ի մինիմում արժեք: Հարկ է նշել, որ այս փոփոխման օրենքը ոչ բոլոր  դեպքերում է աշխատում: Բազմաթիվ իրավիճակներում գրադիենտային իջեցումը  կարող է ձախողել գլոբալ մինիմումի հայտնաբերման խնդրի լուծումը (մենք այս հարցին  կանդրադառնանք հետագա գլուխներում): Սակայն պարզվում է, որ հատկապես նեյրոնային  ցանցերի դեպքում այն հատկապես լավ է աշխատում և արժեքի ֆունկցիան մինիմիզացնելու  բավականին ազդեցիկ մեթոդ է, այսպիսով օգնում է ցանցին սովորել:</p><p></p><p></p><p>  Տպավորություն է, որ գրադիենտային իջեցումը օպտիմալ մարտավարությունն է մինիմումը  հայտնաբերելու համար: Ենթադրենք փորձում ենք կատարել $\Delta v$ քայլ այնպես,  որ $C$-ն նվազի հնարավորինս շատ: Սա համարժեք է $\Delta C \approx \nabla C  \cdot \Delta v$ մինիմիզացնելուն: Սահմանափակենք քայլի չափն այնպես, որ  $\| \Delta v \| = \epsilon$, որտեղ $\epsilon > 0$ և ֆիքսված է: Այլ կերպ  ասած, մեզ պետք է փոքր հաստատուն քայլ, և փորձում ենք գտնել քայլի այնպիսի  ուղղություն, որը $C$-ն կնվազեցնի հնարավորինս շատ: Կարելի է ապացուցել, որ  $\nabla C \cdot \Delta v$-ն մինիմիզացնելու համար $\Delta v$-ի ընտրությունը  կարելի է որոշել $\Delta v = - \eta \nabla C$ արտահայտությամբ, որտեղ  $\eta = \epsilon / \|\nabla C\|$ որոշվում է $\|\Delta v\| = \epsilon$  սահմանափակման միջոցով: Այսպիսով, գրադիենտային իջեցումը կարելի է դիտարկել  որպես փոքր քայլեր վերցնելու մարտավարություն այնպես, որ $C$-ն հնարավորինս նվազի:</p><p>  <h4><a name="exercises_647181"></a><a href="#exercises_647181">Վարժություններ</a></h4>  <ul>    <li> Ապացուցել վերջին պարբերության պնդումը: <em>Հուշում.</em> Եթե դեռ ծանոթ չեք    <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Կոշի-Շվարցի    անհավասարությանը</a>, ապա ծանոթանալը կարող է օգնել այս խնդրի լուծմանը:</p><p>  <li>  Մենք դիտարկեցինք գրադիենտային իջեցումը, երբ $C$-ն երկու կամ ավել փոփոխականների  ֆունկցիա է: Ի՞նչ է տեղի ունենում, երբ $C$-ն մեկ փոփոխականի ֆունկցիա է: Կարո՞ղ  եք բերել գրադիենտային իջեցման երկրաչափական մեկնաբանությունը միաչափ դեպքում:</ul></p><p></p><p>  Գրադիենտային իջեցման բազմաթիվ տարբերակներ են հետազոտվել մինչ այժմ`  ներառելով այնպիսինները, որոնք հիմնված են գնդակի շարժումը կրկնօրինակելու վրա:  Վերջիններս ունեն որոշակի առավելություններ, ինչպես նաև էական խնդիրներ. պարզվում  է, որ պարտադիր է հաշվել $C$-ի երկրորդ կարգի ածանցյալները, ինչը էապես "թանկ"  գործողություն է ալգորոթմական տեսանկյունից: Որպեսզի համոզվենք դրանում, ենթադրենք  մեր նպատակն է հաշվել բոլոր երկրորդ կարգի ածանցյալները`  $\partial^2 C/ \partial v_j \partial v_k$: Եթե $v_j$ փոփոխականների  քանակը մեկ միլիոն է, ապա մենք կարիք կունենայինք հաշվել մոտավորապես տրիլիոն  երկրորդ կարգի մասնակի ածանցյալներ*  <span class="marginnote">    *Իրականում մոտավորապես կես տրիլիոն, քանի որ    $\partial^2 C/ \partial v_j \partial v_k = \partial^2 C/ \partial    v_k \partial v_j$.  Սակայն պարզ է, թե ինչի մասին է խոսքը:  </span>  Դա կլինի էապես թանկարժեք հաշվարկման տեսանկյունից: Հաշվի առնելով վերը նշվածը`  գոյություն ունեն հնարքներ նմանատիպ խնդիրները շրջանցելու համար, ընդ որում,  գրադիենտային իջեցման ալտերնատիվեների որոնումը ակտիվ ուսումնասիրության  ուղղություն է: Այնուամենայնիվ, այս գրքում մենք կօգտագործենք գրադիենտային  իջեցումը որպես հիմնական միջոց նեյրոնային ցանցերի միջոցով ուսուցումը կազմակերպելու  համար:</p><p>  Ինչպե՞ս կարող ենք օգտագործել գրադիենտային իջեցումը նեյրոնային ցանցերով ուսուցման  համար: Գալափարը կայանում է նրանում, որ գրադիենտային իջեցումը օգտագործենք  $w_k$ կշիռները և $b_l$ շեղումները գտնելու համար, որոնք կմինիմիզացնեն արժեքի  <span id="margin_167805660230_reveal" class="equation_link">(6)</span><span id="margin_167805660230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_167805660230_reveal').click(function() {$('#margin_167805660230').toggle('slow', function() {});});</script> ֆունկցիան:  Որպեսզի տեսնենք, թե ինչպես է այն աշխատում, արտագրենք գրադիենտային  իջեցման թարմացման օրենքը` $v_j$ փոփոխականները փոխարինելով կշիռներով  և շեղումներով: Այսպիսով, գրադիենտային իջեցման թարմացման կանոնը կունենա  հետևյալ տեսքը.  <a class="displaced_anchor" name="eqtn16"></a>  <a class="displaced_anchor" name="eqtn17"></a>\begin{eqnarray}    w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\    b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.  \tag{17}\end{eqnarray}  Շարունակաբար իրացնելով այս թարմացման օրենքը, մենք "կգլորվենք բլուրից ներքև"  և ամենայն հավանականությամբ կգտնենք արժեքի ֆունկցիայի մինիմումը: Այլ կերպ ասած,  սա այն օրենքն է, որի միջոցով նեյրոնային ցանցերը կսովորեն:</p><p>  Գրադիենտային իջեցման կիրառման հետ կապված կան որոշակի բարդություններ:  Մենք դրանք խորությամբ կդիտարկենք ապագա գլուխներում: Այժմ դիտարկենք  դրանցից մեկը միայն, որի համար դիտարկենք քառակուսային արժեքի հավասարումը  <span id="margin_786090300230_reveal" class="equation_link">(6)</span><span id="margin_786090300230" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_786090300230_reveal').click(function() {$('#margin_786090300230').toggle('slow', function() {});});</script>:  Նկատենք, որ արժեքի ֆունկցիան ունի $C = \frac{1}{n} \sum_x C_x$ տեսքը,  հետևաբար, այն առանձին մուտքային տվյալնիեր համար $C_x \equiv \frac{\|y(x)-a\|^2}{2}$  արժեքների  հանրահաշվական միջինն է: Պրակտիկորեն, որպեսզի հաշվարկենք $\nabla C$  գրադիենտը, մենք պետք է հաշվարկենք $\nabla C_x$ առանձին ամեն $x$ մուտքային  տվյալի համար, այնուհետև հաշվենք նրանց $\nabla C = \frac{1}{n} \sum_x \nabla C_x$  հանրահաշվական միջինը: ժբախտաբար շատ մեծ քանակությամբ ուսուցման տվյալների դեպքում  սա կարող է բավական շատ ժամանակ տևել, հետևաբար ուսուցումը կարող է դանդաղ տեղի ունենալ:</p><p>  Ուսուցումն արագացնելու նպատակով կարելի է օգտագործել մի գաղափար, որը կոչվում է  <em>ստոկաստիկ գրադիենտային իջեցում (stochastic gradient descent)</em>:  Գաղափարը կայանում է նրանում, որ պետք է $\nabla C$ գրադիենտը գնահատել`  հաշվելով ուսուցման տվյալներից փոքրիկ մասի $\nabla C_x$ գրադիենտները: Պարզվում է,  որ միջինացնելով այդ փոքր հատվածի գրադիենտները՝, մենք արագորեն կարող ենք ստանալ  իսկական $\nabla C$ գրադիենտի լավ գնահատական: Դա օգնում է արագացնել գրադիենտային  իջեցումը, հետևաբար նաև ուսուցումը:</p><p>  Այսպիսով, ստոկաստիկ գրադիենտային իջեցումը աշխատում է` պատահականորեն ընտրելով  որոշակի ոչ մեծ քանակությամբ $m$ ուսուցման մուտքային տվյալներ: Նշանակենք այդ տվյալները  որպես $X_1, X_2, \ldots, X_m$ և պայմանավորվենք հղվել նրանց որպես <em> մինի-փաթեթ  (mini-batch)</em>: Եթե $m$-ը բավականաշափ մեծ է, սպասվում է, որ $\nabla C_{X_j}$-ի  հանրահաշվական միջինը մոտ կլինի $\nabla C_x$ հանրահաշվական միջինին: Այսպիսով,  <a class="displaced_anchor" name="eqtn18"></a>\begin{eqnarray}    \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,  \tag{18}\end{eqnarray}  որտեղ երկրորդ գումարը ամբողջ ուսուցման տվյալների երկայնքով է: Փոխելով հավասարման  կողմերը, կստանանք  <a class="displaced_anchor" name="eqtn19"></a>\begin{eqnarray}    \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},  \tag{19}\end{eqnarray}  միևնույն ժամանակ համոզվելով, որ մենք կարոլ ենք գնահատել ամբողջ գրադիենտը միայն  հաշվելով պատահականորեն ընտրված մինի-փաթեթի գրադիենտները:</p><p>  Որպեսզի սա ուղղակիորեն կապենք նեյրոնային ցանցերով ուսուցման հետ,  ենթադրենք, որ $w_k$ և $b_l$-ով նշանակված են մեր ցանցի կշիռներն ու  շեղումները: Ապա, ստոկաստիկ գրադիենատային իջեցումը աշխատում է  պատահականորեն ընտրված ուսուցման տվյալների մինի-փաթեթի տվյալների  հիման վրա`  <a class="displaced_anchor" name="eqtn20"></a><a class="displaced_anchor" name="eqtn21"></a>\begin{eqnarray}    w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}    \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\    b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}    \sum_j \frac{\partial C_{X_j}}{\partial b_l},  \tag{21}\end{eqnarray}  որտեղ գումարը մինի-փաթեթի բոլոր $X_j$ ուսուցման օրինակների երկայնքով է:  Այնուհետև ընտրում ենք ուրիշ պատահականորեն ընտրված մինի-փաթեթ և կատարում  ուսուցումը դրանց հիման վրա: Սա կատարում ենք այնքան ժամանակ, մինչև  օգտագործած լինենք բոլոր ուսուցման մուտքային տվյալները: Այս պրոցեսը այլ կերպ  կոչվում է ուսուցման <em>դարաշրջան (epoch)</em>: Երբ ավարտում ենք ներկա  ուսուցման դարաշրջանը, սկսում ենք նորն իրականացնել:</p><p>  Հարկ է նշել, որ արժեքի ֆունկցիայի և կշռի ու շեղումների մինի-փաթեթային թարմացումների  տարատեսակ մաշտաբավորումներ (scaling) են ընդունված: Դիտարկենք  <span id="margin_84852336525_reveal" class="equation_link">(6)</span><span id="margin_84852336525" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv    \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_84852336525_reveal').click(function() {$('#margin_84852336525').toggle('slow', function() {});});</script>  հավասարումը, որտեղ արժեքի ֆունկցիան մաշտաբավորված է $\frac{1}{n}$-ով: Մարդիկ  երբեմն բաց են թողնում $\frac{1}{n}$-ը, գումարելով արանձին ուսուցման օրինակների  արժեքի ֆունկցիաները միջինացնելու փոխարեն: Սա կարող է օգտակար լինել, եթե  ուսուցման օրինակների բազմությունը նախապես հայտնի չէ (օրինակ, երբ իրական ժամանակում  տվյալ է գեներացվում): Նույն կերպ մինի-փաթեթի<span id="margin_517690364363_reveal" class="equation_link">(20)</span><span id="margin_517690364363" class="marginequation" style="display: none;"><a href="chap1.html#eqtn20" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}  \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}</a></span><script>$('#margin_517690364363_reveal').click(function() {$('#margin_517690364363').toggle('slow', function() {});});</script>  և  <span id="margin_863737688414_reveal" class="equation_link">(21)</span><span id="margin_863737688414" class="marginequation" style="display: none;"><a href="chap1.html#eqtn21" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}    b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}    \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}</a></span><script>$('#margin_863737688414_reveal').click(function() {$('#margin_863737688414').toggle('slow', function() {});});</script>  թարմացման կանոնները երբեմն բաց են փողնում $\frac{1}{m}$ գործակիցը  գումարի դիմացից: Կոնցեպտուալ առումով, սա էական փոփոխություն չի  մտցնում, քանի որ այն համարժեք է ուսուցման գործակցի վերամաշտաբավորման  (rescaling): Սակայն արժե "աչքը չկտրել այս մասով":</p><p>  Մենք կարող ենք ստոկաստիկ գրադիենտային իջեցման մասին մտածել, որպես  քաղաքական ցուցակագրում. շատ ավելի հեշտ է օգտագործել փոքր մինի-փաթեթ,  քան կիրառել գրադիենտային իջեցումն ամբողջ փաթեթի վրա, ինչպես, օրինակ,  շատ ավելի հեշտ է կատարել քաղաքական հարցում բնակչության մի հատվածի վրա,  քան իտականացնել ընտրություններ: Օրինակ, եթե ունենք $n = 60,000$ ուսուցման  տվյալներ, ինչպես MNIST-ում է, և ընտրենք որպես մինի-փաթեթի երկարություն  $m = 10$, ապա կունենանք գրադիենտի մոտարկման արագության $6,000$  անգամ լավացում: Իհարկե մոտարկումը կատարյալ չի լինի, կլինեն ստատիստիկ  տատանումներ, բայց այն կարիք էլ չունի կատարյալ լինելու: Մեզ հետաքրքրում է  միայն շարժվել այն ուղղությամբ, որը կնվազեցնի $C$-ն: Եվ դա նշանակում է, որ  մենք կարիք չունենք գրադիենտի ավելորդ հաշվարկում: Պրակտիկորեն, ստոկաստիկ  գրադիենտային իջեցումը հաճախակի օգտագործվող և հզոր մոտեցում է նեյրոնային  ցանցերով ուսուցման հարցում և այն հիմքն է բազմաթիվ ուսուցման հմտությունների,  որոնք մենք կկառուցենք այս գրքում:</p><p></p><p></p><p></p><p></p><p></p><p>  <h4><a name="exercise_263792"></a><a href="#exercise_263792">Վարժություն</a></h4>  <ul>    <li>      Գրադիենտային իջեցման ծայրահեղ տարբերակ է 1 մինի փաթեթով գրադիենտային      իջեցումը: Այսպիսով, տրված է $x$ ուսուցման մուտքը, կշիռներն ու շեղումները      թարմացվում են $w_k \rightarrow w_k' =      w_k - \eta \partial C_x / \partial w_k$ and $b_l \rightarrow b_l' =      b_l - \eta \partial C_x / \partial b_l$ օրենքի համաձայն: Այնուհետև ընտրում ենք      ևս մեկ մուտք և թարմացնում կշիռներն ու շեղումները ևս մեկ անգամ և այսպես շարունակ:      Այս պրոցեսը հայտնի է որպես <em>առցանց (online)</em> կամ <em>աճող (incremental)</em>      ուսուցում: Առցանց ուսուցման ժամանակ նեյրոնային ցանցը սովորում է` ամեն պահի օգտագործելով      ճիշտ մեկ ուսուցման տվյալ (այնպես ինչպես մարդիկ են սովորում): Նշեք  առցանց ուսուցման մեկ      առավելությու և մեկ թերություն համեմատած ստոկաստիկ գրադիենտային ուսուցման հետ, որն      օգտագործում է ասենք $20$ չափանի մինի փաթեթ:  </ul></p><p>  Սահմանափակենք այս հատվածը քննարկելով մի հարց, որը երբեմն շփոթեցնում է  մարդկանց, ովքեր նոր են ծանոթանում գրադիենտային իջեցմանը: Նեյրոնային  ցանցերում $C$ արժեքը ֆունկցիա է բազմաթիվ փոփոխականներից (բոլոր կշիռներն  ու շեղումները) և սահմանում է հարթություն բազմաչափ տարածության մեջ: Որոշ  մարդիկ սկսում են անհանգստանալ, թե պետք է պատկերել բոլոր այդ տարածությունները,  որի խնդիրը կայանում է նրանում, որ շատերը կարծում են, որ իրենք չեն կարող պատկերել  կամ պատկերացնել 3-ից ավել տարածություններ: Գոյություն ունի՞ այնպիսի մի հատուկ  կարողություն, որ այդ մարդիկ բաց են թողնում, այնպիսի կարողություն, որ իրական սուպեր  մաթեմատիկոսները ունեն: Իհարկե պատասխանն է ոչ: Անգամ ամենից արհեստավարժ  մաթեմատիկոսները չեն կարող պատկերել 4 չափանի տարածությունները հասկանալի ձևով:  Փոխարենը նրանք օգտագործում են ներկայացման այլընտրանքային միջոցներ կառուցելու  հնարքներ: Դա այն է ինչ մենք արեցինք վերևում. մենք տեսողականի փոխարեն  օգտագործեցինք $\Delta C$ ներկայացնելու հանրահաշվական տեսքը, որպեսզի հասկանանք,  թե ինչպես նվազեցնենք $C$-ն: Մարդիկ, ովքեր կարողանում են էֆֆեկտիվ մտածել  բազմաչափ տարածություններում, ունեն այլ տարբեր հնարքների մտավոր գրադարան.  մեր հանրահաշվական միջոցը միայն մեկ օրինակ է: Այդպիսի հնարքներ կարելի է սովորել,  չնայած նրանցից շատերը չունեն եռաչափ տարածություն պատկերելու պարզպւթյունները:  Այս թեմայով հետաքրքրվողներին հրավիրում ենք ընթերցել <a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">հետևյալ զրույցը</a> այն  բանի մասին, թե ինչպես են մատեմատիկոսներն օգտագործում որոշ հնարքներ  բազմաչափ տարածություններում մտածելու համար: Կարող է քննարկված հնարքներից  որոշները բավականին բարդ լինեն, սակայն մեծ մասը ինտուտիվ է և հասանելի և  և կամայական մարդ կարող է տիրապետել բավարար ջանք գործադրելուց հետո:</p><p></p><p>  <h3>    <a name="implementing_our_network_to_classify_digits"></a>    <a href="#implementing_our_network_to_classify_digits">Թվանշաններ ճանաչող ցանցի իրականացումը</a>  </h3></p><p>  Առաջարկում եմ կառուցել ծրագիր, որը սովորում է, թե ինչպես ճանաչել  ձեռագիր թվանշանները` օգտագործելով ստոկաստիկ գրադիենտային վայրէջքը  և MNIST ուսուցման տվյալների բազմությունը: Որպես առաջին գործողություն  փորձենք համակարգչում զետեղել MNIST տվյալները: Եթե դուք <tt>git</tt>  տարբերակների կառավարման (version control) գործիքի օգտագործող եք, ապա  կարող եք ձեռք բերել տվյալները կլոնավորելով սույն գրքի կոդի շտեմարանից,</p><p>  <div class="highlight">    <pre>git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git</pre>  </div></p><p>  Եթե դուք չեք օգտագործում <tt>git</tt>, ապա կարող եք ներբեռնել տվյալներն  ու կոդը <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">այստեղից</a></p><p>  Ի դեպ, երբ ավելի վաղ նկարագրում էինք MNIST տվյալները, նշեցինք, որ այն  բաժանված է 60,000 ուսուցման և 10,000 թեստավորման նկարներից: Դա  պաշտոնական նկարագրությունն է: Իրականում, մենք պատրաստվում ենք տվյալները  բաժանել այլ կերպ: Առաջարկում եմ թողնել թեստավորման նկարները նույնը, սակայն  բաժնենք MNIST-ի 60,000 ուսուցման նկարները երկու մասի. նկարների 50,000-անոց  բազմություն, որը կօգտագործենք որպես ուսուցման տվյալներ և նկարների 10,000-անոց  բազմություն, որը կօգտագործենք որպես <em>վավերացման բազմություն (validation  set)</em>: Այս գլխում վավերացման բազմությունը չենք օգտագործի, սակայն ավելի  ուշ կօգտագոեծենք այն, որպեսզի որոշենք նեյրոնային ցանցերի <em>հիպեր  պարամետրերը(hyper-parameters)</em>` ուսուցման գործակիցը (learning rate)  և այլն: Չնայած նրան, որ վավերացման տվյալները օրիգինալ MNIST սպեցիֆիկացիայի մաս  չէ, շատերն օգտագործում են MNIST-ն այդ կերպ և վավերացման տվյալների  օգտագործումը հայտնի տարածված պրակտիկա է նեյրոնային ցանցերում: Այսպիսով,  այսուհետ, երբ հղում կատարենք MNIST ուսուցմճն տվյալներին, ապա դա կնշանակի հղում  50,000 տվյալներին*  <span class="marginnote">    *Ինչպես ավելի վաղ նշվել էր, MNIST տվյալների բազմությունը հիմնված NIST-ի    (United States' National Institute of Standards and Technology)    կողմից հավաքագրված երկու տվյալների բազմությունների հիման վրա: MNIST    կառուցելու համար, NIST-ի տվյալները Յանն Լեքունի, Կորինա Կորտեսի և    Քրիստոֆեր Ջեյ ՍԻ Բուրգեսի կողմից ենթարկվել են ֆորմատի փոփոխության`    տվյալների հետ աշխատանքն ավելի հարմարավետ դարձնելու նպատակով: Մանրանասների    համար, այցելեք <a href="http://yann.lecun.com/exdb/mnist/">    այս հղումը</a>: Այս գրքի կոդի շտեմարանում տվյալներն այնպիսի տեսքով են,    որը հեշտացնում է բեռնումն ու Python-ի միջոցով մանիպուլյացիաների    իրականացումը: Ես ձեռք եմ բերել այս տվյալների այսպիսի տեսքը Մոնրեալի    Համալսարանի LISA մեքենայական ուսուցման լաբարատորիայից <a href="http://www.deeplearning.net/tutorial/gettingstarted.html">link</a>):  </span></p><p></p><p>  MNIST տվյալներից բացի մեզ պետք է նաև Python-ի  <a href="http://numpy.org">Numpy</a> կոչվող գրադարանը, որպեսզի  իրականացնենք գխային հանրահաշվի խնդիրները: Գրադարանը կարող եք տեղադրել   <a href="http://www.scipy.org/install.html">այստեղից</a>:</p><p>  Թույլ տվեք, մինչ ամբողջական ներկայացնելը, նկարագրել նեյրոնային ցանցերի կոդի հիմնական  մասերը: Կարևորագույն կտորը դա <tt>Network</tt> դասն է, որը ներկայացնում է նեյրոնային  ցանցը: Ահա <tt>Network</tt> օբյեկտի կոնստրուկտորը:</p><p><div class="highlight"><pre><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span></pre></div></p><p>  Այս կոդում <tt>sizes</tt> ցուցակը պարունակում է համապատասխան շերտերում  նեյրոնների քանակը: Օրինակ, երբ ցանկանում ենք ստեղծել <tt>Network</tt> օբյեկտ,  որի առաջին շերտը կազմված է 2 նեյրոններից, երկրորդ շերտը կազմված է 3 նեյրոններից և  վերջին երրորդ շերտը կազմված է 1 նեյրոնից, ապա կարող ենք դա իրականացնել հետևյալ  կոդի միջոցով.<div class="highlight">  <pre>    <span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  </pre></div><a name="weight_initialization"></a>  <tt>Network</tt> օբյեկտի շեղումների և կշիռների արժեքները սկզբնավորվում են պատահական  մեծություններով` օգտագործելով Numpy գրադարանի <tt>np.random.randn</tt> ֆունկցիան, որը  գեներացնում է Գաուսյան բաշխում $0$ միջինով և $1$ միջին քառակուսային շեղումով: Այսպիսի  պատահական արժեքներով սկզբնավորումը հանդիսանում է որպես սկզբնակետ ստոկաստիկ գրադիենտային վայրէջքի  ալգորիթմի աշխատանքի համար: Հետագա գլուխներում կդիտարկենք կշիռների սկզբնավորման  ավելի լավ եղանակներ, իսկ առայժմ բավարարվենք այս մեթոդով: Նկատենք, որ <tt>Network</tt>  դասի սկզբնավորման կոդում ենթադրվում է, որ նեյրոնների առաջին շերտը մուտքայինն է, այդ իսկ պատճառով  բաց է թողնվում այդ շերտի համար շեղումների սկզբնավորումը, քանի որ շեղումներն օգտագործվում  են միայն հետագա շերտերում արժեքներ հաշվելիս:</p><p>  Նկատենք նաև, որ շեղումներն ու կշիռները պահվում են որպես Numpy մատրիցներ:  Օրինակ, <tt>net.weights[1]</tt>-ը Numpy մատրից է, որում պահվում են երկրորդ  և երրորդ շերտերն իրար կապող կշիռները (այլ ոչ առաջին և երկրորդ շերտերը, քանզի Python-ի  ցուցակների ինդեքսավորումը սկսվում է <tt>0-ից</tt>): Քանի որ <tt>net.weights[1]</tt>  երկար է գրվում, ապա պարզապես նշանակենք այն $w$-ով: Այն այնպիսի մատրից է, որի $w_{jk}$  անդամը ցույց է տալիս երկրորդ շերտի $k^{\rm րդ}$ և երրորդ շերտի $j^{\rm րդ}$ նեյրոններին կապող  կշիռը: թվում է, թե $j$ և $k$ ինդեքսների հերթականությունն ավելի ինտուիտիվ կլիներ, եթե դիրքերով  շրջված լինեին, սակայն այդպիսի հերթականության առավելությունը կայանում է նրանում, որ  երրորդ շերտի ելքային արժեքների վեկտորը կարող ենք գրել որպես  <a class="displaced_anchor" name="eqtn22"></a>    \begin{eqnarray}      a' = \sigma(w a + b).    \tag{22}\end{eqnarray}  Փորձենք բացատրել այս հավասարման կառուցվածքը: $a$-ն նեյրոնների երկրորդ շերտի ելքային  արժեքների(ակտիվացիաների) վեկտորն է: $a'$ ստանալոյ համար $a$-ն բազմակատկվում է  $w$ մատրիցով, որին ավելացվում է $b$ շեղումների վեկտորը: Այնուհետև $\sigma$-ն կիրառում ենք  էլեմենտ առ էլեմենտ $w a +b$ վեկտորի վրա (նշենք, որ ֆունկցիայի էլեմենտ առ էլեմենտ կիրառումը  վեկտորի վրա կոչվում է ֆունկցիայի <em>վեկտորացում</em>): Հեշտ է համոզվել, որ <span id="margin_621803496648_reveal" class="equation_link">(22)</span><span id="margin_621803496648" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_621803496648_reveal').click(function() {$('#margin_621803496648').toggle('slow', function() {});});</script>  հավասարումը տալիս է նույն արժեքը, ինչ ավելի վաղ մեր դուրս բերած<span id="margin_466969638583_reveal" class="equation_link">(4)</span><span id="margin_466969638583" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_466969638583_reveal').click(function() {$('#margin_466969638583').toggle('slow', function() {});});</script>  հավասարումը, որը հաշվում է սիգմոիդ նեյրոնի ելքային արժեքը:</p><p>  <h4><a name="exercise_997362"></a><a href="#exercise_997362">Վարժություն</a></h4>  <ul><li> Ցույց տվեք, որ <span id="margin_44996869809_reveal" class="equation_link">(22)</span><span id="margin_44996869809" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_44996869809_reveal').click(function() {$('#margin_44996869809').toggle('slow', function() {});});</script>  հավասարումը նույն արդյունքն է տալիս, ինչ  rule <span id="margin_325948154784_reveal" class="equation_link">(4)</span><span id="margin_325948154784" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_325948154784_reveal').click(function() {$('#margin_325948154784').toggle('slow', function() {});});</script>  արտահայտությունը սիգմոիդ նեյրոնների ելքային արժեքի հաշվման համար:</ul></p><p>  Հաշվի առնելով այս ամենը, դյուրին է կառուցել <tt>Network</tt>-ի ելքային արժեքը հաշվող  ծրագրի իրականացումը: Սկսենք սիգմոիդի ֆունկցիայի սահմանումից.<div class="highlight"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span></pre></div>  Նկատենք, որ <tt>z</tt> մուտքային պարամետրի վեկտոր կամ Numpy զանգված լինելու  դեմքում Numpy-ը ինքնաբերաբար էլեմենտ առ էլեմենտ կիրառում է <tt>sigmoid</tt>  ֆունկցիան, հետաբար այն վեկտորացված է:</p><p>  Այնուհետև ավելացնենք <tt>Network</tt> դասի <tt>feedforward</tt> մեթոդը, որը  տրված ցանցի <tt>a</tt> մուտքային պարամետրի դեպքում վերադարձնում է համապաասխան արժեքը  *<span class="marginnote">** Ենթադրվում է, որ <tt>a</tt> մուտքային պարամետրը <tt>(n, 1)</tt> միջակայքում  գտնվող Numpy ndarray է, այլ ոչ <tt>(n,)</tt> չափանի վեկտոր: Այստեղ <tt>n</tt>-ը ցանցի  մուտքային վեկտորի երկարությունն է: Եթե փորձեք <tt>(n,)</tt> վեկտոր օտգագործել որպես մուտքային  արժեք, ապա տարօրինակ արդյունքներ կստացվեն: Չնայած նրան, որ <tt>(n,)</tt> վեկտորի  օգտագործումը ավելի բնական ընտրություն է թվում, <tt>(n, 1)</tt> չափանի ndarray-ի օգտագործումը  բավականին հեշտացնում է կոդի այնպիսի փոփոխությունները, որի արդյունքում կարող ենք միաժամանակ մեկից ավելի  մուտքային արժեքներով կատարենք մարզումը, որը երբեմն հարմարավետ է: </span>:  Մեթոդը պարզապես կիրառում է  <span id="margin_608357269255_reveal" class="equation_link">(22)</span>  <span id="margin_608357269255" class="marginequation" style="display: none;">    <a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">      \begin{eqnarray} a' = \sigma(w a + b) \nonumber\end{eqnarray}    </a>  </span>  <script>    $('#margin_608357269255_reveal').click(function() {$('#margin_608357269255').toggle('slow', function() {});});  </script>  հավասարումը շերտ առ շերտ.  <div class="highlight"><pre>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>        <span class="sd">&quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;</span>        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>        <span class="k">return</span> <span class="n">a</span></pre></div></p><p>  Իհարկե, մեր հիմնական նպատակն է <tt>Network</tt> օբյեկտների ուսուցումը:  Այդ իսկ պատճառով իրականացնենք <tt>SGD</tt> ստոկաստիկ գրադիենտային  վայրէջքի ալգորիթմը: Ահա իրականացումը: Այն կարող է փոքր ինչ խորհրդավոր թվալ  որոշ վայրերում, սակայն մենք մանրամասն կդիտարկենք քիչ ուշ:</p><p>  <div class="highlight"><pre>    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span><span class="sd">        gradient descent.  The &quot;training_data&quot; is a list of tuples</span><span class="sd">        &quot;(x, y)&quot; representing the training inputs and the desired</span><span class="sd">        outputs.  The other non-optional parameters are</span><span class="sd">        self-explanatory.  If &quot;test_data&quot; is provided then the</span><span class="sd">        network will be evaluated against the test data after each</span><span class="sd">        epoch, and partial progress printed out.  This is useful for</span><span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>                <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>            <span class="k">else</span><span class="p">:</span>                <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span></pre></div></p><p>  <tt>training_data</tt>-ն <tt>(x, y)</tt> զույգերի ցուցակ է, որը ներկայացնում  է մարզման մուտքային տվյալները և համապատասխան ցանկալի ելքային արժեքները:  <tt>epochs</tt> և <tt>mini_batch_size</tt> փոփոխականները ներկայացնում են  մարզման դարաշրջանների քանակը և մինի-փաթեթների չափը  տվյալների նմուշագրման (sampling) ժամանակ: <tt>eta</tt>-ն $\eta$ ուսուցման  գործակիցն է: Եթե <tt>test_data</tt> տրված է, ապա ծրագիրը կգնահատի ցանցը  յուրաքանչյուր մարզման դարաշրջանից հետո և կարտատպի մասնակի առաջխաղացումները:  Այն օգտակար է, որպեսզի հետևենք ծրագրի պրոգրեսին, սակայն դա մյուս կոմից կարող է  էապես դանդաղեցնել ծրագիրը:</p><p>  Կոդն աշխատում է հետևյալ կերպ: Յուրաքանչյուր դարաշրջանում այն սկսում է  մարզման տվյալները պատահական խառնելուց այնուհետև բաժանում է համապատասխան  երկարության մինի-փաթեթների: Դա մարզման տվյալների պատահական մնուշագրման հեշտ  ձև է: Այնուհետև յուրաքանչյուր <tt>mini_batch</tt>-ի համար կիրառում ենք  գրադիենտային վայրէջքի մեկ քայլ: Դա կատարվում է <tt>self.update_mini_batch(mini_batch, eta)</tt>  կոդի միջոցով, որը ցանցի կշիռներն ու շեղումները թարմացնում է գրադիենտային իջեցման  մեկ իտերացիայի հիման վրա՝ օգտագործելով միայն <tt>mini_batch</tt>-ում  գտնվող մարզման տվյալները: Ահա <tt>update_mini_batch</tt> մեթոդի կոդը.  <div class="highlight"><pre>    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>  <span class="sd">        gradient descent using backpropagation to a single mini batch.</span>  <span class="sd">        The &quot;mini_batch&quot; is a list of tuples &quot;(x, y)&quot;, and &quot;eta&quot;</span>  <span class="sd">        is the learning rate.&quot;&quot;&quot;</span>          <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>          <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>          <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>              <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>              <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>              <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>          <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>                          <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>          <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>                         <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>  </pre></div>  Հիմնական գործը կատարվում է հետևալ տողում  <div class="highlight"><pre>    <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  </pre></div>  Այն կանչում է <em>backpropagation</em> ալգորիթմը, որը գնային ֆունկցիայի  գրադիենտի հաշվման արագ միջոց է: Այսպիսով, <tt>update_mini_batch</tt>  պարզապես հաշվում է <tt>mini_batch</tt>-ի յուրաքանչյուր մարզման օրինակի  գրադիենտները, ապա համապատասխանաբար թարմացնում <tt>self.weights</tt>  կշիռների արժրքները և <tt>self.biases</tt> շեղումները:</p><p>  <tt>self.backprop</tt>-ի կոդը դեռևս չենք դիտարկի: Մենք կսովորենք  հետադարձ տարածման (backpropagation) աշխատանքը հաջորդ գլխում, այդ թվում  նաև կդիտարկենք <tt>self.backprop</tt>-ի կոդը: Այժմ պարզապես ենթադրենք,  որ այն աշխատում է վերը նշվածի համաձայն՝ վերադարձնելով <tt>x</tt> մարզման  օրինակին համապատասխան գնի գրադիենտը:</p><p>  Այժմ դիտարկենք ամբողջական ծրագիրը, այդ թվում նաև դոկումենտացիան, որը  վերևում բաց էր թպղնված: <tt>self.backprop</tt>-ից զատ, ծրագիրը ինքն իրեն  նկարագրում է՝ <tt>self.SGD</tt>-ում և <tt>self.update_mini_batch</tt> -ում  տեղի են ունենում հիմնական գործողությունները, որոնք արդեն քննարկել ենք: <tt>self.backprop</tt>-ն  օգտագործում է մի քանի հավելյալ ֆունկցիաներ գրադիենտների հաշվման նպատակով  (<tt>sigmoid_prime</tt>-ը, որը հաշվում է $\sigma$ ֆունկցիայի ածանցյալը  և <tt>self.cost_derivative</tt>-ը, որը հաշվում է գնի ածանցյալը): Այդ ֆունկցիաներն  այստեղ չենք նկարագրի, քանի որ դրանք մանրամասն կդիտարկենք հաջորդ գլխում:  Չնայած այն փաստին, որ ծրագիրը ֆիզիկապես երկար է, կոդի մեծ մասը կազմում են  բացատրական մեկնաբանության համար գրված տողերը: Ամբողջական կոդը կարելի է գտնել  GitHub-ում՝ <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py">այստեղ</a>։</p><p></p><p>  <div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>  <span class="sd">network.py</span>  <span class="sd">~~~~~~~~~~</span>  <span class="sd">A module to implement the stochastic gradient descent learning</span>  <span class="sd">algorithm for a feedforward neural network.  Gradients are calculated</span>  <span class="sd">using backpropagation.  Note that I have focused on making the code</span>  <span class="sd">simple, easily readable, and easily modifiable.  It is not optimized,</span>  <span class="sd">and omits many desirable features.</span>  <span class="sd">&quot;&quot;&quot;</span>  <span class="c">#### Libraries</span>  <span class="c"># Standard library</span>  <span class="kn">import</span> <span class="nn">random</span>  <span class="c"># Third-party libraries</span>  <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>  <span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;The list ``sizes`` contains the number of neurons in the</span>  <span class="sd">        respective layers of the network.  For example, if the list</span>  <span class="sd">        was [2, 3, 1] then it would be a three-layer network, with the</span>  <span class="sd">        first layer containing 2 neurons, the second layer 3 neurons,</span>  <span class="sd">        and the third layer 1 neuron.  The biases and weights for the</span>  <span class="sd">        network are initialized randomly, using a Gaussian</span>  <span class="sd">        distribution with mean 0, and variance 1.  Note that the first</span>  <span class="sd">        layer is assumed to be an input layer, and by convention we</span>  <span class="sd">        won&#39;t set any biases for those neurons, since biases are only</span>  <span class="sd">        ever used in computing the outputs from later layers.&quot;&quot;&quot;</span>          <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>          <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>          <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>          <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>                          <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>      <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Return the output of the network if ``a`` is input.&quot;&quot;&quot;</span>          <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>              <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>          <span class="k">return</span> <span class="n">a</span>      <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>              <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>  <span class="sd">        gradient descent.  The ``training_data`` is a list of tuples</span>  <span class="sd">        ``(x, y)`` representing the training inputs and the desired</span>  <span class="sd">        outputs.  The other non-optional parameters are</span>  <span class="sd">        self-explanatory.  If ``test_data`` is provided then the</span>  <span class="sd">        network will be evaluated against the test data after each</span>  <span class="sd">        epoch, and partial progress printed out.  This is useful for</span>  <span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>          <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>          <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>          <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>              <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>              <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>                  <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>                  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>              <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>                  <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>              <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>                  <span class="k">print</span> <span class="s">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>                      <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>              <span class="k">else</span><span class="p">:</span>                  <span class="k">print</span> <span class="s">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>      <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>  <span class="sd">        gradient descent using backpropagation to a single mini batch.</span>  <span class="sd">        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``</span>  <span class="sd">        is the learning rate.&quot;&quot;&quot;</span>          <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>          <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>          <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>              <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>              <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>              <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>          <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>                          <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>          <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>                         <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>      <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the</span>  <span class="sd">        gradient for the cost function C_x.  ``nabla_b`` and</span>  <span class="sd">        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar</span>  <span class="sd">        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;</span>          <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>          <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>          <span class="c"># feedforward</span>          <span class="n">activation</span> <span class="o">=</span> <span class="n">x</span>          <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="c"># list to store all the activations, layer by layer</span>          <span class="n">zs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># list to store all the z vectors, layer by layer</span>          <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>              <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>              <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>              <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>              <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>          <span class="c"># backward pass</span>          <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_derivative</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> \              <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>          <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>          <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>          <span class="c"># Note that the variable l in the loop below is used a little</span>          <span class="c"># differently to the notation in Chapter 2 of the book.  Here,</span>          <span class="c"># l = 1 means the last layer of neurons, l = 2 is the</span>          <span class="c"># second-last layer, and so on.  It&#39;s a renumbering of the</span>          <span class="c"># scheme in the book, used here to take advantage of the fact</span>          <span class="c"># that Python can use negative indices in lists.</span>          <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>              <span class="n">z</span> <span class="o">=</span> <span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>              <span class="n">sp</span> <span class="o">=</span> <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>              <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">sp</span>              <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>              <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>          <span class="k">return</span> <span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)</span>      <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Return the number of test inputs for which the neural</span>  <span class="sd">        network outputs the correct result. Note that the neural</span>  <span class="sd">        network&#39;s output is assumed to be the index of whichever</span>  <span class="sd">        neuron in the final layer has the highest activation.&quot;&quot;&quot;</span>          <span class="n">test_results</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">y</span><span class="p">)</span>                          <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>          <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">)</span>      <span class="k">def</span> <span class="nf">cost_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_activations</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>          <span class="sd">&quot;&quot;&quot;Return the vector of partial derivatives \partial C_x /</span>  <span class="sd">        \partial a for the output activations.&quot;&quot;&quot;</span>          <span class="k">return</span> <span class="p">(</span><span class="n">output_activations</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>  <span class="c">#### Miscellaneous functions</span>  <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>      <span class="sd">&quot;&quot;&quot;The sigmoid function.&quot;&quot;&quot;</span>      <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>  <span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>      <span class="sd">&quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;</span>      <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>  </pre></div></p><p>  Ինչքա՞ն հաջողությամբ է ծրագիրը ճանաչում ձեռագիր թվանշանները: Սկսենք  MNIST-ի տվյալները բեռնելուց: Մենք դա կանենք՝ օգտագործելով հետևյալ փոքրիկ  օգնական ծրագիրը՝ <tt>mnist_loader.py</tt>, որը նկարագրված է ներքևում:  Աշխատեցնենք հետևյալ հրամանները Python-ի վահանակում:</p><p>  <div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">mnist_loader</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> \  <span class="o">...</span> <span class="n">mnist_loader</span><span class="o">.</span><span class="n">load_data_wrapper</span><span class="p">()</span>  </pre></div></p><p>  Իհարկե, սա կարելի էր իրականացնել առանձին Python ծրագրում, սակայն  ամենայն հավանականությամբ ամենադյուրինը Python-ի վահանակում այն իրականացնելն է:</p><p>  MNIST-ի տվյալները բեռելուց հետո կստեղծենք <tt>Network</tt> $30$ թաքնված  նեյրոններով։ Մենք դա անում ենք վերևում սահմանված <tt>network</tt> անունով  ծրագիրը ներմուծելուց հետո.</p><p>  <div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">network</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>  </pre></div></p><p>  Վերջապես, կօգտագործենք ստոկաստիկ գրադիենտայի իջեցում, որպեսզի սովորենք MNIST-ից  կառուցված <tt>training_data</tt>-ից 30 դարաշրջանների ընթացքում, որտեղ մինի-փաթեթի  երկարությունն ընտրված է 10 և ուսուցման գործակիցը՝ $\eta = 3.0$</p><p>  <div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>  </pre></div></p><p>  Նկատենք, որ եթե ծրագիրն աշխատեցնում եք գիրքը կարդալուն զուգընթաց, ապա որոշ  ժամանակ կպահանջվի այն մինչև վերջ աշխատացնելու վրա: Ես առաջարկում եմ,  որպեսզի ծրագիրը միացնեք, որպեսզի այն աշխատի և շարունակեք կարդալը և  ժամանակ առ ժամանակ ստուգեք կոդի տպած ելքերը տերմինալում: Եթե շտապում եք,  ապա կարող եք աշխատանքն արագացնել դարաշրջանները նվազեցնելով, կամ նվազեցնելով  թաքնված նեյրոնների քանակը կամ օգտագործելով միայն մարզման տվյալների մի մասը:  Պետք է նշել, որ արտադրական (production) կոդն անհամեմատ ավելի արագ կաշխատեր.  հետևյալ Python սկրիտպները նախատեսված են ոչ թե լինելու արտադրությունում աշխատող  արագագործ ծրագրեր, այլ օգնելու ընթերցողին Նեյրոնային ցանցերի աշխատանքը հասկանալու:  Եվ, իհարկե, նեյրնոային ցանցերը մարզելուց հետո այն բավականին արագագործ կլինի  համարյա բոլոր պլատֆորմներում: Օրինակ, այն բանից հետո, երբ մենք ուսուցանենք  կշիռների և շեղումնիեր բավարար լավ գուշակող բազմություն, ապա այն կարող ենք  տեղափոխել, օրինակ բրաուզերային միջավայր և աշխատացնել Javascript-ի միջոցով  կամ իրականացնել նույնը որևիցէ մոբայլ պլատֆորմի վրա, որպես բնիկ (native) ծրագիր:  Ահա որոշակի մաս նեյրոնային ցանցի մեկ մարզման աշխատանքից: հետևյալ տրանսկրիպտը ցույց է  տալիս, թե քանի փորձնական նկար է ճանաչվել նեյրոնային ցանցի կողմից մարզման  յուրաքանչյուր դարաշրջանից հետո: Ինչպես կարող եք տեսնել, միայն մեկ դարաշրջանից  հետո այն հասել է 10,000-ից 9,129 ճշգրիտ ճանաչման և այդ թիվը շարունակում է աճել:</p><p>  <div class="highlight">    <pre>      Epoch 0: 9129 / 10000      Epoch 1: 9295 / 10000      Epoch 2: 9348 / 10000      ...      Epoch 27: 9528 / 10000      Epoch 28: 9542 / 10000      Epoch 29: 9534 / 10000    </pre>  </div></p><p>  Այսպիսով, մարզված ցանցը տալիս է մոտավորապես $95$ տոկոս ճշտությամբ  դասակարգում՝ $95.42$ լինելով ամենաբարձր դասակարգման ճշտության արժեքը ("Epoch 28")։  Դա բավականին ոգևորիչ է առաջին քայլի համար: Սակայն հաշվի առեք խնդրում եմ,  որ երբ դուք աշխատեցնեք ծրագիրն, ապա ձեզ մոտ ստացված արժեքները կարող են  տարբերվել ինձ մոտ ստացված արժեքներից քանի որ ցանցի սկզբնարժեքավորումն  իրականացվում է պատահականության սկզբունքով, որի հետևանքով տարբեր  արժեքներ կունենան կշիռներն ու շեղումները: Այս գլխում տեղ գտած արժեքները երեք  փորձի արդյունքում ստացված արդյունքներից լավագույնն է:</p><p>  Վերագործարկենք վերևում գրված ծրագիրը՝ թաքնված նեյրոնների քանակը դարձնելով  $100$։ Ինչպես արդեն նշել էինք, եթե ծրագիրը գործարկում եք կարդալուն զուգընթաց,  ապա հաշվի առեք, որ որոշակի ժամանակ կպահանջվի մինչև ծրագրի աշխատանքը վերջանա  (իմ մեքենայի վրա այս փորձարկումը տևում է տասնյակ վայրկյաններ յուրաքանչյուր մարզման  դարաշրջանի համար), հետևաբար իմաստալից կլինի շարունակել կարդալը ծրագրի  աշխատանքին զուգընթաց:</p><p>  <div class="highlight">    <pre>      <span class="o">&gt;&gt;&gt;</span>      <span class="n">net</span>      <span class="o">=</span>      <span class="n">network</span>      <span class="o">.</span>      <span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span></pre></div></p><p>  Իհարկե, սա արդյունքները բարելավում է $96.59$ տոկոսի: Գոնե այս դեպքում,  ավել թաքնված նեյրոններ օգտագործելն օգնում է ստանալ բարելավված արդյունքներ  *<span class="marginnote">    *Ընթերցողների հետադարձ կապը այս փորձարկման համար ցույց է տալիս    արդյունքների տարբերություն և որոշ մարզումների արդյունքները ընդհուպ հուսադրող    չեն։ Երրորդ գլխում ներկայացված տեխնիկաները էապես կնվազեցնեն կատարողականության    տարբերությունները մեր ցանցի տարբեր մարզումներից հետո։  </span>։</p><p>  Իհարկե, այս ճշգրտությունները ստանալիս, կատարվել է մարզման դարաշրջանների քանակի,  մինի-փաթեթի չափի և $\eta$ մարզման գործակցի ընտրություններ: Ինչպես նշված է  վերևում, այս պարամետրերը կոչվում են նեյրոնային ցանցի հիպերպարամետրեր,  որպեզի տարբերենք իրենց ցանցի այն պարամետրերից(կշիռներ և շեղումներ),  որոնք ուսուցանվում են մարզման ընթացքում: Եթե հիպերպարամետրերը հաջող չընտրենք,  կարող է լավ արդյունքներ չստանանք։ Ենթադրենք, որ ուսուցման գործակիցն ընտրել ենք  որպես $\eta = 0.001$</p><p>  <div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>  </pre></div></p><p>  Արդյունքներն ավելի քիչ հուսադրող են.  <div class="highlight"><pre>Epoch 0: 1139 / 10000  Epoch 1: 1136 / 10000  Epoch 2: 1135 / 10000  ...  Epoch 27: 2101 / 10000  Epoch 28: 2123 / 10000  Epoch 29: 2142 / 10000  </pre></div>  Սակայն նկատենք, որ ցանցի կատարողականությունը դանդաղորեն բարելավվում է  ժամանակի ընթացքում։ Ինչի հետևանքով հանգում ենք այն եզրակացության, որ  կարելի է ուսուցման գործակցի արժեքը մի փոքր էլ մեծացնել $\eta = 0.01$։  Եթե կատարենք այդ գործողությունը, ապա կնկատենք, որ արդյունքները բարելավվել են։  (Եթե նմանատիպ փոփոխությունները դրական ազդեցություն են ունենում, փորձեք նորից  կատարել այդ փոփոխություններից)։ Եթե հետևենք այս խորհրդին և մի քանի անգամ կատարենք  նմանատիպ փոփոխություն, ապա կստանանք ուսուցման գործակցի նմանատիպ արժեք՝  $\eta = 1.0$ (ընդհուպ հասցնելով մինչև $3.0$), որը մոտիկ է ավելի վաղ փորձերին։  Այսպիսով, նույնիսկ եթե հիպեր-պարամետրերի սկզբանական ընտրությունը կատարյալ չէ,  մենք ունենք հնարավորություն հիպեր-պարամետրերի ընտրությունը բարելավելու։</p><p>  Ընդհանուր առմամբ նեյրոնային ցանցերի վրիպազերծումը (debugging) կարող է  դժվարություններ առաջացնել։ Դա հատկապես տեղի ունի, երբ հիպեր-պարամետրերի  ընտրությունը հանգեցնում է պատահական աղմուկի (random noise)։ Ենթադրենք,  որ մենք փորձում ենք 30 թաքնված նեյրոններով ցանցային հաջողված արխիտեկտուրա,  որի ուսուցման գործակիցը $\eta = 100.0$ է։  <div class="highlight"><pre><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>  </pre></div>  Այս դեպքում ուսուցման գործակիցը շատ բարձր է.  <div class="highlight"><pre><span class="n">Epoch</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="n">Epoch</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="n">Epoch</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="n">Epoch</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="o">...</span>  <span class="n">Epoch</span> <span class="mi">27</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="n">Epoch</span> <span class="mi">28</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>  <span class="n">Epoch</span> <span class="mi">29</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>  </pre></div>  Այժմ պատկերացնենք, որ մենք առաջին անգամն էինք փորձում լուծել այս խնդիրը։  Իհարկե, մեր նախորդ փորձերից <em>գիտենք</em>, որ ուսուցման գործակցի  նվազեցումը ճիշտ մոտեցում է։ Սակայն, եթե այս խնդրին առաջին անգամ հանգեինք,  ապա ելքային արժեքը բավարար չէր լինի, որպեսզի մեզ ուղղորդեր ճիշտ քայլերի։ Մի  գուցե մենք անհանգստանայինք ոչ միայն ուսուցման գործակցի այլև նայերոնային ցանցերի  մնացած այլ ասպեկտների մասին։ Մի գուցե մտածեինք արդյոք կշիռներն ու շեղումները  սկզբնարժեքավորել ենք այնպես, որ նեյրոնային ցանցի մարզումը դժվարանու՞մ է։ Կամ միգուցե  մենք չունե՞նք բավարար քանակությամն մարզման տվյալներ։ Իսկ կարող է բավարար  քանակությամբ դարաշրջանների համար չե՞նք գործարկել ցանցը։ Միգուցե այսպիսի նեյրոնային  ցանցերի կառուցվածքով հնարավոր չէ սովորել ձեռագիր թվանշնանների ճանաչումը։ Երևի ուսուցման  գործակիցն է շատ <em>ցածր</em> կամ շատ <em>բարձր</em>։ Խնդրին առաջին անգամ  մոտենալուց հիմնականում բազմաթիվ հարցեր են առաջանում։</p><p>  Այս ամենից հետևությունն այն է, որ նեյրոնային ցանցերի վրիպազերծումը տրիվիալ չէ  և պահանջում է հատուկ մոտեցումներ, որոնք պետք է յուրացնել, եթե նպատակ ունեք  լավ արդյունքներ ստանալ նեյրոնային ցանցերից։ Ընդհանրապես, մեզ պետք են լավ  հիպերպարամետրեր և կառուցվածք ընտրելու մոտեցումներ։ Այս թեմայով մենք կխոսենք ամբողջ  գրքի ընթացքում, ներառյալ նաև, թե ինչպես ենք վերևի հիպերպարամետրերն ընտրելու։</p><p><h4><a name="exercise_420023"></a><a href="#exercise_420023">Վարժություն</a></h4><ul></p><p>  <li>    փորձեք կառուցել երկշերտ ցանց միայն մուտքային և ելքային շերտերով՝ համատա    784 և 10 նեյրոններով։ Մարզեք ցանցը ստոկաստիկ գրադիենտային վայրէջքի միջոցով։    Ինչպիսի՞ ճշտությամբ դասակարգում կարող եք ստանալ։
</ul></p><p></p><p>  Նկատենք, որ մենք բաց ենք թողել MNIST տվյալների բեռնման մանրամսները։  Ահա, տեսեք կոդը ներքևում. MNIST տվյալների պահման համար օգտագործվող  տվյալների կառուցվածքները ներկայացված են մեկնաբանություններում։ Այն բավականին պարզ է՝  ցուցակներ և շարքեր արտահայտված Numpy <tt>ndarray</tt> օբյեկտների միջոցով  (եթե ծանոթ չեք <tt>ndarray</tt>-ների հետ, ապա պատկերացրեք այդ տվյալների տիպերը
  որպես վեկտորներ).</p><p>  <div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>  <span class="sd">mnist_loader</span>  <span class="sd">~~~~~~~~~~~~</span>  <span class="sd">A library to load the MNIST image data.  For details of the data</span>  <span class="sd">structures that are returned, see the doc strings for ``load_data``</span>  <span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>  <span class="sd">function usually called by our neural network code.</span>  <span class="sd">&quot;&quot;&quot;</span>  <span class="c">#### Libraries</span>  <span class="c"># Standard library</span>  <span class="kn">import</span> <span class="nn">cPickle</span>  <span class="kn">import</span> <span class="nn">gzip</span>  <span class="c"># Third-party libraries</span>  <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>  <span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>      <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>  <span class="sd">    the validation data, and the test data.</span>  <span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>  <span class="sd">    The first entry contains the actual training images.  This is a</span>  <span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>  <span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>  <span class="sd">    pixels in a single MNIST image.</span>  <span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>  <span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>  <span class="sd">    values (0...9) for the corresponding images contained in the first</span>  <span class="sd">    entry of the tuple.</span>  <span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>  <span class="sd">    each contains only 10,000 images.</span>  <span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>  <span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>  <span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>  <span class="sd">    below.</span>  <span class="sd">    &quot;&quot;&quot;</span>      <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;../data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">)</span>      <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>      <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>      <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>  <span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>      <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>  <span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>  <span class="sd">    convenient for use in our implementation of neural networks.</span>  <span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>  <span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>  <span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>  <span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>  <span class="sd">    correct digit for ``x``.</span>  <span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>  <span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>  <span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>  <span class="sd">    corresponding classification, i.e., the digit values (integers)</span>  <span class="sd">    corresponding to ``x``.</span>  <span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>  <span class="sd">    the training data and the validation / test data.  These formats</span>  <span class="sd">    turn out to be the most convenient for use in our neural network</span>  <span class="sd">    code.&quot;&quot;&quot;</span>      <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>      <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>      <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>      <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>      <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>      <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>      <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>      <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>      <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>  <span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>      <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>  <span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>  <span class="sd">    (0...9) into a corresponding desired output from the neural</span>  <span class="sd">    network.&quot;&quot;&quot;</span>      <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>      <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>      <span class="k">return</span> <span class="n">e</span>  </pre></div></p><p>  Ինչպես վերևում նշել եմ, մեր ծրագիրը ցույց է տալիս բավականին լավ արդյունքներ։  Սակայն ի՞նչ է դա նշանակում։ Ինչպե՞ս է որոշվում լավ կամ վատ արդյունքը։ Օրինակ  ինֆորմատիվ է կառուցել պարզ (ոչ նեյրոնային ցանց) հիմքային տեստեր համեմատության
  համար, որպեսզի հասկանանք, թե ինչ է նշանակում լավ արդյունք ունենալ։ Իհարկե, ամենից  պարզ տեստը դա պատահականորեն գուշակված թվանշանն է, որը կգուշակի մոտավորապես  տաս տոկոս ճշտությամբ։ Հարկ է նշել, որ մեր ալգորիթմը էապես ավելի ճշգրիտ է։

  I said above that our program gets pretty good results.  What doesthat mean?  Good compared to what?  It's informative to have somesimple (non-neural-network) baseline tests to compare against, tounderstand what it means to perform well.  The simplest baseline ofall, of course, is to randomly guess the digit.  That'll be rightabout ten percent of the time.  We're doing much better than that!</p><p>  Ի՞նչ կասեք ավելի քիչ տրիվիալ թեստի մասին։ Փորձենք բավականին պարզ գաղափար.  մենք կդիրարկենք նկարի <em>մգությունը</em>։ Օրինակ, $2$ թվանշանին համապատասխանող  նկարը սովորաբար ավելի մուգ կլինի, քան $1$-ի նկարը, քանի որ ավելի շատ պիքսելներ են սև։
  Տես ներքևում պատկերված օրինակը
  What about a less trivial baseline?  Let's try an extremely simpleidea: we'll look at how <em>dark</em> an image is.  For instance, animage of a $2$ will typically be quite a bit darker than an image of a$1$, just because more pixels are blackened out, as the followingexamples illustrate:</p><p>  <center><img src="images/mnist_2_and_1.png" width="256px"></center></p><p>  Օգտագործենք մարզման տվյալները $0, 1, 2,\ldots, 9$ թվանշանների համար
  միջին մգությունը հաշվելու համար։ Յուրաքանչյուր նկարի համար, կհաշվենք մգությունը,
  այնուհետև համեմատելով, կգտնենք ամենամոտիկ միջին մգությամբ նկարը, որը կօգտագործենք  գուշակման համար։ Դա պարզ պրոցեդուրա է և համապատասխան կոդի իրականացնելը դժվար չէ։  Հետևաբար այն չենք ներկայացնի այս էջում, իսկ հետաքրքրվողների համար այն
  կարելի է գտնել հետևյալ հղումով
  <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub  repository</a>  Սա էական բարելավում է պատահական գուշակման համեմատ, որի հետևանքով  $10,000$-ից $2,225$ թվանշանները ճիշտ են գուշակվում, ինչը նշանակում է  $22.25$ տոկոս ճշտություն։  This suggests using the training data to compute average darknessesfor each digit, $0, 1, 2,\ldots, 9$.  When presented with a new image,we compute how dark the image is, and then guess that it's whicheverdigit has the closest average darkness.  This is a simple procedure,and is easy to code up, so I won't explicitly write out the code -if you're interested it's in the<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub  repository</a>.
  But it's a big improvement over random guessing,getting $2,225$ of the $10,000$ test images correct, i.e., $22.25$percent accuracy.</p><p>  <a name="SVM"></a></p><p>  Դժվար չէ գտնել այլ իդեաներ, որոնք հասնում են $20$-ից $50$ տոկոս ճշտության։  Եթե ավելի շատ փորձեք, կարող եք նաև $50$ տոկոսն անցնել։ Սակայն ավելի մեծ
  ճշտությունների հասնելու համար օգտակար է այլ մեքենայական ուսուցման ալգորիթմների  օգտագործումը։ Փորձենք օգտագործել ամենահայտնի ալգորիթմերից մեկը՝ <em>support vector  machine</em> կամ <em>SVM</em>։ Եթե ծանոթ չեք SVM-ների հետ, ապա մի անհանգստացէք,  քանի որ մենք կարիք չենք ունենալու հասկանալ, թե SVM-ներն ինչպես են աշխատում։ Դրա
  փոխարեն կօգտագործենք Python-ի գրադարանը, որը կոչվում է  <a href="http://scikit-learn.org/stable/">scikit-learn</a>, որը Python-ի պարզ  միջերես (interface) է SVM-ների համար, որը հայտնի է որպես
  <a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>։
  It's not difficult to find other ideas which achieve accuracies in the$20$ to $50$ percent range.  If you work a bit harder you can get upover $50$ percent.  But to get much higher accuracies it helps to useestablished machine learning algorithms.  Let's try using one of thebest known algorithms, the <em>support vector  machine</em>or <em>SVM</em>.  If you're notfamiliar with SVMs, not to worry, we're not going to need tounderstand the details of how SVMs work.  Instead, we'll use a Pythonlibrary called<a href="http://scikit-learn.org/stable/">scikit-learn</a>,which provides a simple Python interface to a fast C-based library forSVMs known as<a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>.</p><p>  Եթե գործարկենք scikit-learn-ի SVM դասակարգիչը՝ օգտագործելով լռելյայն (default)  կարգավորումները, ապա կստանանք 10,000-ից 9,435 թեստային նկարների ճիշտ դասակարգում։  (Կոդը հասանելի է
  <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">այստեղ</a>.)
  Սա էական բարելավում է՝ համեմատած դասակարգման մեր նախորդ ավելի պարզ մոտեցումների։  SVMի արդյունավետությունը շատ մոտ է մեր նեյրոնային ցանցին, սակայն փոքր-ինչ զիջում է։  Հետագա գլուխներում կներկայացնենք նոր մոտեցումներ, որոնք թույլ են տալիս բարելավել
  նեյրոնային ցանցերն այնպես, որ իրենց ճշգրտությունն էապես բարձր է SVM-ներից։
  If we run scikit-learn's SVM classifier using the default settings,then it gets 9,435 of 10,000 test images correct.  (The code isavailable<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">here</a>.)That's a big improvement over our naive approach of classifying animage based on how dark it is.  Indeed, it means that the SVM isperforming roughly as well as our neural networks, just a littleworse.  In later chapters we'll introduce new techniques that enableus to improve our neural networks so that they perform much betterthan the SVM.</p><p>  Սակայն դա վերջը չէ։ 10,000-ից 9,435 ճիշտ արդյունքը դեռ ստացվում է scikit-learn-ի
  SVM-ների համար նախատեսված լռելյայն կարգավորումներով։ SVM-ներն ունեն բազմաթիվ  պարամետրեր, որոնք կարելի է փոխել և արդյունքն էլ ավելի բարելավել։ Ավելի լավ պարամետրերը  կարելի է որոշակի մեխանիզմներով փնտրել, որը այստեղ չենք իրականցնի, սակայն կարող եք  հղվել <a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">հետևյալ բլոգային գրառմանը,</a>
  որի հեղինակն է <a href="http://peekaboo-vision.blogspot.ca/">Անդրեաս Մյուլլերը</a>,  եթե հետաքրքրված եք ավելին իմանալու։ Մյուլլերը ցույց է տալիս, որ պարամետրերը օպտիմալացնելու  որոշակի աշխատանք կատարելուց հետո կարելի է ճշգրտությունը հասցնել մինչև 98.5 տոկոսի։ Այլ կերպ
  ասած, լավ կարգավորված SVM-ը սխալվում է ամեն 70 թվանշանը մեկ։ Դա բավականին լավ է։ Կարո՞ղ
  է արդյոք նեյրոնային ցանցը ավելի արդյունավետ լինել։

  That's not the end of the story, however.  The 9,435 of 10,000 resultis for scikit-learn's default settings for SVMs.  SVMs have a numberof tunable parameters, and it's possible to search for parameterswhich improve this out-of-the-box performance.  I won't explicitly dothis search, but instead refer you to<a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">this  blog post</a> by <a href="http://peekaboo-vision.blogspot.ca/">Andreas  Mueller</a> if you'd like to know more.  Mueller shows that with somework optimizing the SVM's parameters it's possible to get theperformance up above 98.5 percent accuracy.  In other words, awell-tuned SVM only makes an error on about one digit in 70.  That'spretty good!  Can neural networks do better?</p><p>  Փաստացի, կարող են։ Ներկայումս, լավ նախագծված նեյրոնային ցանցը ավելի
  ճշգրիտ է, քան մնացած հայտնի MNIST-ի լուծման մեթոդները, այդ թվում նաև SVM-ները։
  Ներկայիս (2013) դասակարգման ռեկորդը 10,000-ից 9,979 ճիշտ նկարների ճանաչումն է։
  Այդ արդյունքը գրանցվել է<a href="http://www.cs.nyu.edu/&#126;wanli/">Լի Վուանի (Li
  Wan)</a>, <a href="http://www.matthewzeiler.com/">Մաթյու Զեիլերի (Matthew Zeiler)</a>,
  Սիքսին Ժանգի (Sixin Zhang), <a href="http://yann.lecun.com/">Յան Լեքունի (Yann LeCun)</a>
  և <a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Ռոբ Ֆերգյուսի (Rob Fergus)</a>
  կողմից։ Գրքում հետագայում մենք կտեսնենք իրենց օգտագործած մեթոդների մեծ մասը։
  Այդ մակարդակի վրա արտադրողականությունը բավականին մոտ է մարդկանց և վիճելորեն
  ավելի լավը, քանի որ որոշ MNIST նկարներ նույնիսկ մարդկանց համար են դժվարություն
  ներկայացնում ճանաչման առումով

  In fact, they can.  At present, well-designed neural networks
outperform every other technique for solving MNIST, including SVMs.The current (2013) record is classifying 9,979 of 10,000 imagescorrectly.  This was done by <a href="http://www.cs.nyu.edu/&#126;wanli/">Li  Wan</a>, <a href="http://www.matthewzeiler.com/">Matthew Zeiler</a>, SixinZhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, and<a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Rob Fergus</a>.We'll see most of the techniques they used later in the book.  At thatlevel the performance is close to human-equivalent, and is arguablybetter, since quite a few of the MNIST images are difficult even forhumans to recognize with confidence, for example:</p><p>  <center><img src="images/mnist_really_bad_images.png" width="560px"></center></p><p>
  Բավականին տպավորիչ է, որ այնպիսի նկարներն ինչպիսին MNIST-ի նկարներն են,
  նեյրոնային ցանցերը կարող են 21-ից բացի բոլոր 10,000 նկարները ճիշտ դասակարգեն։
  Սովորաբար, ծրագրավորելիս, մենք համոզված ենք, որ MNIST թվանշանների ճանաչման
  խնդրի պես դժվար խնդիր լուծելիս անհրաժեշտ է դժվար ալգորիթմ։ Սակայն նույնիսկ
  Վուան <em>և այլոք</em> (Wan <em>et al</em>) հոդվածում նշված նեյրոնային ցանցերը
  ներգրավում են բավականին պարզ ալգորիթմներ, որի որոշակիորեն ձևափոխված տարբերակին
  ականատես եղանք այս գլխում։ Ամբողջ բարդությունն ինքնևստինքյան ուսուցանվում է
  տվյալներից։ Ինչ-որ իմաստով կարելի է ասել, որ մեր ստացած երկու արդյունքների և
  նրանց, որոնք գրված են բազմաթիվ հոդվածներոմ, կապվում են իրար հետ հետևյալ
  գաղափարով.

  <center>
    բարդ ալգորիթմ $\leq$ պարզ ուսուցման ալգորիթմ + լավ մարզման տվյալներ։
</center>

  I trust you'll agree that those are tough to classify!  With imageslike these in the MNIST data set it's remarkable that neural networkscan accurately classify all but 21 of the 10,000 test images.Usually, when programming we believe that solving a complicatedproblem like recognizing the MNIST digits requires a sophisticatedalgorithm.  But even the neural networks in the Wan <em>et al</em> paperjust mentioned involve quite simple algorithms, variations on thealgorithm we've seen in this chapter.  All the complexity is learned,automatically, from the training data. In some sense, the moral ofboth our results and those in more sophisticated papers, is that forsome problems:<center>  sophisticated algorithm $\leq$ simple learning algorithm + good  training data.</center></p><p>  <h3>
    <a name="toward_deep_learning"></a>
    <a href="#toward_deep_learning">Դեպի խորը ուսուցում</a></h3>
</p><p>  Մեր նեյրոնային ցանցի արտադրողականությունը բավականին տպավորիչ է,
  սակայն միևնույն ժամանակ միստիկ։ Ցանցի կշիռներն ու շեղումները ավտոմատ
  կերպով են հայտնաբերվել։ Եվ դա նշանակում է, որ մենք չունենք անմիջական
  բացատրություն, թե ինչպես է ցանցը իրականացնում այն ինչ իրականացնում է։
  Կարո՞ղ ենք արդյոք ինչ-որ կերպ հասկանալ մեր ցանցի՝ ձեռագիր թվանշաններ
  ճանաչելու սկզբունքները։ Եվ, եթե գիտենք այդ սկզբունքները, կարո՞ղ ենք բարելավել
  արդյունքները։
</p><p>
  Ենթադրենք, որ մի քանի տասնամյակ հետո նեյրոնային ցանցերը հանգեցնում են
  Արհեստական Ինտելեկտի (ԱԻ)։ Կկարողանա՞նք մենք արդյոք հասկանալ ինչպես է
  այդպիսի ինտելեկտն աշխատում։ Կարող է ցանցերը ոչ թափանցիկ լինեն մեզ համար,
  որի կշիռներն ու շեղումները մենք չենք հասկանա, քանի որ դրանք ուսուցանվել են
  ավտոմատ կերպով։ Արհեստական Ինտելեկտի ուսումնասիրությունների վաղ ժամանակներում
  մարդիկ հույս ունեին, որ ԱԻ ստեղծելու ջանքերը միաժամանակ կօգնեին մեզ հասկանալ
  ինտելեկտի սկզբունքները կամ նույնիսկ մարդկային ուղեղի աշխատանքի գաղտնիքները։
  Սակայն կարող է արդյունքում մենք ո'չ ուղեղի աշխատանքը հասկանանք, ո'չ էլ արհեստական
  ինտելեկտի։

  To put these questions more starkly, suppose that a few decades hence
neural networks lead to artificial intelligence (AI).  Will weunderstand how such intelligent networks work?  Perhaps the networkswill be opaque to us, with weights and biases we don't understand,because they've been learned automatically.  In the early days of AIresearch people hoped that the effort to build an AI would also helpus understand the principles behind intelligence and, maybe, thefunctioning of the human brain.  But perhaps the outcome will be thatwe end up understanding neither the brain nor how artificialintelligence works!</p><p>
  Որպեսզի փորձենք պատասխանել այս հարցերին, առաջարկում եմ վերադառնալ արհեստական
  նեյրոնների ինտերպրետացիային, որ ես տվել էի այս գլխի սկզբում։ Ենթադրենք, որ մեր
  նպատակն է որոշել արդյոք նկարում մարդկային դեմք է, թե ոչ.

  To address these questions, let's think back to the interpretation ofartificial neurons that I gave at the start of the chapter, as a meansof weighing evidence.  Suppose we want to determine whether an imageshows a human face or not:</p><p> </p><p>  <span class="marginnote">Credits: 1. <a  href="http://commons.wikimedia.org/wiki/User:ST">Ester Inbar</a>. 2.  Unknown. 3. NASA, ESA, G. Illingworth, D. Magee, and P. Oesch  (University of California, Santa Cruz), R. Bouwens (Leiden  University), and the HUDF09 Team.  Click on the images for more  details.</span>
</p>

<p>  <a
  href="http://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG"><img  src="images/Kangaroo.JPG" height="190px"/></a> <a  href="http://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img  src="images/Einstein_crop.jpg" height="190px"/></a> <a  href="http://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img  src="images/hubble.jpg" height="190px"/></a>

</p>

<p>
  Այս խնդրին կարող ենք մոտենալ այնպես ինչպես ձեռագրերի ճանաչման խնդրին՝
  օգտագործելով նկարի պիքսելները որպես նեյրոնային ցանցի մուտք այնպես, որ նեյրոնային
  ցանցն ունենա մեկ ելքային նեյրոն, որը ցույց կտա կամ «այո, սա դեմք է» կամ
  «ոչ, սա դեմք չէ»։
</p><p>
  Ենթադրենք, որ վարվում ենք հենց այդպես, սակայն այս դեպքում ուսուցման
  ալգորիթմ չենք օգտագործում։ Փոխարենը, ցանցը կձևավորենք ձեռքով՝ ընտրելով
  համապատասխան կշիռերն ու շեղումները։ Իսկ ինչպե՞ս կիրականացնեինք դա։
  Ժամանակավորապես մոռանալով նեյրոնային ցանցերի մասին, կարող ենք խնդիրը
  բաժանել ենթախնդիրների. օրինակ ոնկարի ձախ վերևի անկյունում աչք գոյություն ունի՞։
  Ունի այն արդյոք աչք աջ վերևի անկյունում։ Արդյո՞ք այն քիթ ունի միջնամասում։
  Արդյո՞ք այն ունի բերան միջնամասից ներքև գտնվող մասում և այլն …
</p>

<p>
  Եթե այս հարցերից որոշների պատասխանը «այո» է կամ նույնիսկ «հավանաբար այո»,
  ապա մենք կեզրակացնեինք, որ նկարն ամենայն հավանականությամբ դեմք է։ Եվ հակառակը,
  եթե այս հարցերի մեծամասնության պատասխանը «ոչ» է, ապա նկարն ամենայն հավանականությամբ
  դեմք չէ։
</p><p>
  Իհարկե, սա բավականին կոշտ մեթոդ է և ունի բազում խնդիրներ։ Ճաղատ մարդիկ,
  օրինակ, մազեր չունեն։ Կարոլ է պատահել, որ դեմքը մասնակի է երևում կամ անկյան
  տակ է, ինչի պատճառով որոշ դիմային մասեր տեսանելի չլինեն։ Սակայն, եթե կարողանանք
  լուծել ենթախնդիրները նեյրոնային ցանցերի միջոցով, ապա հավանաբար կարող ենք կառուցել
  դեմքի ճամաչման նեյրոնային ցանց՝ միավորելով ենթախնդիրների նեյրոնային ցանցերը։ Ահա հնարավոր
  նախագիծ, որտեղ ուղղանկյուններով նշված են ենթացանցերը։ Նկատենք, որ սա չենք դիտարկում
  որպես դեմքերի ճանաչման ռեալիստիկ մեթոդ, այլ փորձում ենք ինտուցիա կառուցենք նրա մասին,
  թե ինչպես են ցանցերը աշխատում։ Ահա արխիտեկտուրան.

  Of course, this is just a rough heuristic, and it suffers from many
deficiencies.  Maybe the person is bald, so they have no hair.  Maybewe can only see part of the face, or the face is at an angle, so someof the facial features are obscured.  Still, the heuristic suggeststhat if we can solve the sub-problems using neural networks, thenperhaps we can build a neural network for face-detection, by combiningthe networks for the sub-problems.  Here's a possible architecture,with rectangles denoting the sub-networks.  Note that this isn'tintended as a realistic approach to solving the face-detectionproblem; rather, it's to help us build intuition about how networksfunction.  Here's the architecture:</p><p>  <center><img src="images/tikz14.png"/></center></p><p>
  Հնարավոր է նաև, որ ենթացանցերը իրենց հերթին բաժանված լինեն ենթամասերի։
  Ենթադրենք, որ դիտարկում ենք հետևյալ հարցը՝ «Արդյո՞ք ձախ վերևի անկյունում
  աչք կա»։ Սա կարող է մասնատվել այնպիսի հարցերի, ինչպիսիք են «Արդյո՞ք ունք կա»,
  «Արդյո՞ք թարթիչներ կան» և այլն։ Իհարկե այս հարցերը պետք է պարունակեն նաև
  դիրքային ինֆորմացիա. «Արդյո՞ք ունքը ձախ վերևում է և թարթիչներից վերև և
  նմանատիպ այլ հարցեր, սակայն չբարդացնենք։ «Արդյոք ձախ վերևում ունք կա» հարցը
  արդեն կարելի է մասնատել։

  It's also plausible that the sub-networks can be decomposed.  Supposewe're considering the question: "Is there an eye in the top left?"This can be decomposed into questions such as: "Is there aneyebrow?"; "Are there eyelashes?"; "Is there an iris?"; and soon.  Of course, these questions should really include positionalinformation, as well - "Is the eyebrow in the top left, and abovethe iris?", that kind of thing - but let's keep it simple.  Thenetwork to answer the question "Is there an eye in the top left?"can now be decomposed:</p><p>  <center><img src="images/tikz15.png"/></center></p><p>  Այդ հարցերը նույնպես հնարավոր է մասերի բաժանել բազմաթիվ շերտերով։ Այսպիսով,
  մենք կաշխատենք այնպիսի ենթացանցերի հետ, որոնք պատասխանում են այնպիսի պարզ
  հարցերի, որոնց կարելի է պատասխանել մեկ պիքսելի մակարդակով։ Այդ հարցերը օրինակ
  կարող են լինել հատուկ տեղամասերում պարզագույն ուրվագծերի ներկայության կամ
  բացակայության մասին։ Այդպիսի հարցերին կարող են պատասխանել մեկական նեյրոններ,
  որոնք կապված են նկարի պիքսելներին։

  Those questions too can be broken down, further and further through
multiple layers.  Ultimately, we'll be working with sub-networks thatanswer questions so simple they can easily be answered at the level ofsingle pixels.  Those questions might, for example, be about thepresence or absence of very simple shapes at particular points in theimage.  Such questions can be answered by single neurons connected tothe raw pixels in the image.</p><p>
  Վերջնական արդյունքը դա մի ցանց է, որը այնպիսի բարդ հարցը ինչպիսին է
  «Արդյոք նկարում դեմք է պատկերված» բաժանում է բազմաթիվ շատ փոքր
  հարցերի, որոնց կարելի է պատասխանել մեկ պիքսելի մակարդակով։ Սա իրականացվում
  է բազմաթիվ շերտերի միջոցով, որի սկզբնական շերտերը պատասխանում են տրիվիալ
  հարցերի տարատեսակ ուրվագծերի մասին, իսկ վերին շերտերն արդեն կազմում են
  ավելի կոմպլեքս և աբստրակտ կոնցեպտների մասին հարցերին պատասխանող
  հիերարխիայի գագաթներ։ Այն ցանցերը, որոնք ունեն նմանատիպ բազմաշերտ կառուցվածք
  կազմված երկու և ավել շերտերից կոչվում են <em>խորը նեյրոնային ցանցեր (deep neural networks)</em>

  The end result is a network which breaks down a very complicatedquestion - does this image show a face or not - into very simplequestions answerable at the level of single pixels.  It does thisthrough a series of many layers, with early layers answering verysimple and specific questions about the input image, and later layersbuilding up a hierarchy of ever more complex and abstract concepts.Networks with this kind of many-layer structure - two or more hiddenlayers - are called <em>deep neural networks</em>.</p>
<p></p><p></p>
<p>
  Իհարկե մենք դեռ չենք քննարկել, թե ինչպես կարելի է իրականացնել այդ
  ռեկուրսիվ կազմալուծումը ենթացանցերի։ Անշուշտ ցանցի կշիռներն ու շեղումները
  ձեռքով կառուցելը պրակտիկ չէ։ Իհարկե, մենք կուզենայինք օգտագործել այնպիսի
  ուսուցման ալգորիթմներ, որ ցանցն ավտոմատ կերպով սովորի կշիռներն ու շեղումները,
  հետևաբար նաև կոնցեպտների հիերարխիան՝ մարզման տվյալներից։ 1980-ականներին և
  1990-ականներին հետազոտողները փորձել են մարզել խորը ցանցերը՝ օգտագործելով
  ստոկաստիկ գրադիենտային վայրէջք և հետադարձ տարածում։ Դժբախտաբար, բացի
  որոշ կառուցվածքներից ուրիշ էական հաջողություն չի գրանցվել։ Ցանցը կսովորեր,
  սակայն բավականին դանդաղ և հիմնականում այնքան դանդաղ, որ պրակտիկորեն
  հնարավոր չէր օգտագործել։

Of course, I haven't said how to do this recursive decomposition intosub-networks.  It certainly isn't practical to hand-design the weightsand biases in the network.  Instead, we'd like to use learningalgorithms so that the network can automatically learn the weights andbiases - and thus, the hierarchy of concepts - from training data.Researchers in the 1980s and 1990s tried using stochastic gradientdescent and backpropagation to train deep networks.  Unfortunately,except for a few special architectures, they didn't have much luck.The networks would learn, but very slowly, and in practice often tooslowly to be useful.</p><p>
  2006 թվականից սկսած որոշակի տեխնիկաների խումբ է կառուցվել, որ
  հնարավորություն է տալիս խորը նեյրոնային ցանցերին սովորել։ Այս խորը
  ուսուցման տեխնիկաները հիմնված են ստոկաստիկ գրադիենտային վայրէջքի,
  հետադարձ տարածության և այլ ուրիշ նոր գաղափարների վրա։ Այս մոտեցումները
  հնարավորություն տվեցին ավելի խորը, մեծ և լայն ցանցեր մարզել - մարդիկ այժմ
  հեշտությամբ կարոլանում ենմատզել 5-ից 10 թաքնված շերտերով նեյրոնային ցանցեր։
  Եվ պարզվում է, որ այդպիսի ցանցերն ավելի լավ արտադրողականություն ունեն, քան
  համեմատաբար սաղր ցանցերը, օրինակ մի թաքնված շերտով նեյրոնային ցանցէրը։ Պատճառը,
  իհարկե, այն է, որ խորը նեյրոնային ցանցերը կարողանում են կառուցել կոմպլեքս կոնցեպտների
  հիերարխիա։ Այն որոշ չափով նման է նրան, որ հիմնական ծրագրավորման լեզուները
  օգտագործում են մոդուլար նախագծում և աբստրակցիայի այնպիսի մեխանիզմներ, որ
  հնարավորություն է տալիս ստեղծել կոմպլեքս ծրագրեր։ Խորը ցանցերը սաղր ցանցերին
  համեմատելը նման է ֆունկցիայի կանչի հնարավորությամբ ծրագրավորման լեզվի համեմատությանը
  մի ծրագրավորման լեզվի, որը չունի այդ հնարավորությունը։ Նեյրոնային ցանցերում աբստրակցիան
  այլ տեսք ունի համեմատած ծրագրավորման լեզուների, սակայն այն հավասարապես կարևոր է։

  Since 2006, a set of techniques has been developed that enablelearning in deep neural nets.  These deep learning techniques arebased on stochastic gradient descent and backpropagation, but alsointroduce new ideas.  These techniques have enabled much deeper (andlarger) networks to be trained - people now routinely train networkswith 5 to 10 hidden layers.  And, it turns out that these perform farbetter on many problems than shallow neural networks, i.e., networkswith just a single hidden layer.  The reason, of course, is theability of deep nets to build up a complex hierarchy of concepts.It's a bit like the way conventional programming languages use modulardesign and ideas about abstraction to enable the creation of complexcomputer programs.  Comparing a deep network to a shallow network is abit like comparing a programming language with the ability to makefunction calls to a stripped down language with no ability to makesuch calls.  Abstraction takes a different form in neural networksthan it does in conventional programming, but it's just as important.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></div>
<div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Jan 19 06:09:48 2017
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44208967-1', 'neuralnetworksanddeeplearning.com');
  ga('send', 'pageview');

</script>
</body>
</html>
